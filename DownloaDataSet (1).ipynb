{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYag-Iv5J9BP",
        "outputId": "8559abf5-feb1-474a-a4e3-041aeb732ae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datele au fost salvate în /content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "\n",
        "def download_full_content(link):\n",
        "    try:\n",
        "        response = requests.get(link)\n",
        "        if response.status_code == 200:\n",
        "            return response.text\n",
        "        else:\n",
        "            return \"Failed to download\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "def fetch_arxiv_data():\n",
        "    url = \"http://export.arxiv.org/api/query\"\n",
        "    params = {\n",
        "        \"search_query\": \"all:quantum computing\",\n",
        "        \"start\": 0,\n",
        "        \"max_results\": 500\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Eroare la API: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    root = ET.fromstring(response.text)\n",
        "    ns = {'arxiv': 'http://www.w3.org/2005/Atom'}\n",
        "\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    for i, entry in enumerate(root.findall('arxiv:entry', ns)):\n",
        "        title = entry.find('arxiv:title', ns).text.strip()\n",
        "        authors = \", \".join(author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns))\n",
        "        published = entry.find('arxiv:published', ns).text\n",
        "        summary = entry.find('arxiv:summary', ns).text.strip()\n",
        "        content_link = entry.find('arxiv:id', ns).text\n",
        "\n",
        "\n",
        "        full_content = download_full_content(content_link)\n",
        "\n",
        "\n",
        "        dataset.append({\n",
        "            \"Index\": i + 1,\n",
        "            \"Title\": title,\n",
        "            \"Authors\": authors,\n",
        "            \"Published\": published,\n",
        "            \"Summary\": summary,\n",
        "            \"Content\": full_content\n",
        "        })\n",
        "\n",
        "\n",
        "    output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing.csv\"\n",
        "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(file, fieldnames=[\"Index\", \"Title\", \"Authors\", \"Published\", \"Summary\", \"Content\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(dataset)\n",
        "\n",
        "    print(f\"Datele au fost salvate în {output_file}\")\n",
        "\n",
        "\n",
        "fetch_arxiv_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdbH88QOu6Rc",
        "outputId": "312b8457-8e63-4b8c-a7c9-bf9426baff30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfNTTvdlnkB-",
        "outputId": "01efe29f-15f8-4d72-a666-98fc76f22396"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Datele au fost salvate în /content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import csv\n",
        "import io\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Funcție pentru a descărca și extrage text din PDF\n",
        "def download_pdf_and_extract_text(pdf_url):\n",
        "    try:\n",
        "        response = requests.get(pdf_url)\n",
        "        if response.status_code == 200:\n",
        "            # Deschidem PDF-ul din memorie\n",
        "            pdf_file = io.BytesIO(response.content)\n",
        "            pdf_reader = PdfReader(pdf_file)\n",
        "            text = \"\"\n",
        "            for page in pdf_reader.pages:\n",
        "                text += page.extract_text()\n",
        "            return text.strip() if text else \"No text extracted\"\n",
        "        else:\n",
        "            return \"Failed to download PDF\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Funcție principală\n",
        "def fetch_arxiv_data():\n",
        "    # Setarea URL-ului API-ului ArXiv\n",
        "    url = \"http://export.arxiv.org/api/query\"\n",
        "    params = {\n",
        "        \"search_query\": \"all:quantum computing\",\n",
        "        \"start\": 0,\n",
        "        \"max_results\": 500\n",
        "    }\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    # Verificarea răspunsului\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Eroare la API: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # Parsează XML-ul\n",
        "    root = ET.fromstring(response.text)\n",
        "    ns = {'arxiv': 'http://www.w3.org/2005/Atom'}\n",
        "\n",
        "    # Structura pentru date\n",
        "    dataset = []\n",
        "\n",
        "    # Iterăm prin fiecare intrare\n",
        "    for i, entry in enumerate(root.findall('arxiv:entry', ns)):\n",
        "        title = entry.find('arxiv:title', ns).text.strip()\n",
        "        authors = \", \".join(author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns))\n",
        "        published = entry.find('arxiv:published', ns).text\n",
        "        summary = entry.find('arxiv:summary', ns).text.strip()\n",
        "\n",
        "        # Găsim link-ul către PDF cu titlul \"pdf\"\n",
        "        pdf_link = entry.find('.//arxiv:link[@title=\"pdf\"]', ns)\n",
        "        pdf_url = pdf_link.attrib['href'] if pdf_link is not None else None\n",
        "\n",
        "        # Descărcăm și extragem textul din PDF (dacă există link)\n",
        "        pdf_text = download_pdf_and_extract_text(pdf_url) if pdf_url else \"No PDF available\"\n",
        "\n",
        "        # Adăugăm în dataset\n",
        "        dataset.append({\n",
        "            \"Index\": i + 1,\n",
        "            \"Title\": title,\n",
        "            \"Authors\": authors,\n",
        "            \"Published\": published,\n",
        "            \"Summary\": summary,\n",
        "            \"PDF_Content\": pdf_text\n",
        "        })\n",
        "\n",
        "    # Salvăm dataset-ul într-un fișier CSV\n",
        "    output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "    # with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "    #     writer = csv.DictWriter(file, fieldnames=[\"Index\", \"Title\", \"Authors\", \"Published\", \"Summary\", \"PDF_Content\"])\n",
        "    #     writer.writeheader()\n",
        "    #     writer.writerows(dataset)\n",
        "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
        "        writer = csv.DictWriter(\n",
        "        file,\n",
        "        fieldnames=[\"Index\", \"Title\", \"Authors\", \"Published\", \"Summary\", \"PDF_Content\"],\n",
        "        escapechar='\\\\',\n",
        "        quoting=csv.QUOTE_MINIMAL\n",
        "        )\n",
        "        writer.writeheader()\n",
        "        writer.writerows(dataset)\n",
        "    print(f\"Datele au fost salvate în {output_file}\")\n",
        "\n",
        "# Rulăm funcția\n",
        "fetch_arxiv_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvbsZt_QGzr9",
        "outputId": "411d8688-3ca6-4a04-f005-05da9edadbfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Numărul de intrări în fișierul CSV: 466\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import sys\n",
        "\n",
        "# Mărim limita câmpurilor\n",
        "csv.field_size_limit(sys.maxsize)\n",
        "\n",
        "# Numele fișierului CSV\n",
        "csv_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "def count_entries_in_csv(file_name):\n",
        "    try:\n",
        "        with open(file_name, mode='r', encoding='utf-8') as file:\n",
        "            content = file.read().replace('\\x00', '')  # Eliminăm caracterele NUL\n",
        "            lines = content.splitlines()\n",
        "            reader = csv.DictReader(lines)\n",
        "            entries = list(reader)\n",
        "            print(f\"Numărul de intrări în fișierul CSV: {len(entries)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Fișierul {file_name} nu a fost găsit.\")\n",
        "    except Exception as e:\n",
        "        print(f\"A apărut o eroare: {e}\")\n",
        "\n",
        "# Rulăm funcția\n",
        "count_entries_in_csv(csv_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qClKlK-wIZhy"
      },
      "outputs": [],
      "source": [
        "pip install lambeq qiskit pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225,
          "referenced_widgets": [
            "452b0143cd3e4790b7592593063e4a0b",
            "f5ca20fdcdc64eee89655539ecf76925",
            "1143e2d95c5a45208fcaf2c479da3995",
            "d640f2706cdd4b43acbbeb40f4f774c7",
            "9b171099b7a34c98928e10cbe9792593",
            "64edcbfd544d45daa11bbb687552e05f",
            "80dcd5582380403ab63ea99d23f0317e",
            "c42c78409e644f69b9b82a5aa0df9cb5",
            "2d314f23d63244d6b59acde7f9882597",
            "9a1dd51c33414094bd32704c42cc6f14",
            "4ced78a61b7e4a01ba1bb198fd18f0c6",
            "36447226f91941c1a40bf1cfe3fe7663",
            "ec5052134301476490dd9d2ba8de10de",
            "c3b7b85bc182462f8fce0df209d590f2",
            "25b358003faa4f53bb0103116237c949",
            "3145e7029f52479ea38f93d49496e1ee",
            "08979dbc6d9b4f16a76d6565a059be73",
            "13a473b654594a48aa8bb39eee15e506",
            "899efb3cde3a496fa0b0b2cc7a37d8dc",
            "aa44c5c6da90435996395596f136d2d5",
            "bdc68ca2e7874e4dbe37ddcb581b0dce",
            "f63c897a352643c5a68484f5ac0571ee"
          ]
        },
        "id": "kEAxClnMEBlr",
        "outputId": "e1483f30-e760-4a51-bc3d-d5147c3cb5cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "452b0143cd3e4790b7592593063e4a0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model: 0.0%|          |0.000/1.533GB [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36447226f91941c1a40bf1cfe3fe7663",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Evaluating checksum: 0.0%|          |0.000/1.533GB [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting model...\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from lambeq import BobcatParser\n",
        "\n",
        "parser = BobcatParser()\n",
        "diagram = parser.sentence2diagram('This is a test sentence')\n",
        "diagram.draw()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "SvT55m6IMB4m",
        "outputId": "3b2cb992-4721-4b79-b893-c11e59507923"
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'SpacyLemmatizer' from 'lambeq' (/usr/local/lib/python3.10/dist-packages/lambeq/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-a80d4187c5df>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlambeq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSpacyTokeniser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpacyLemmatizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpacyStopwordRemover\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBobcatParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Inițializează instrumentele de procesare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtokeniser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSpacyTokeniser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'SpacyLemmatizer' from 'lambeq' (/usr/local/lib/python3.10/dist-packages/lambeq/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from lambeq import SpacyTokeniser, SpacyLemmatizer, SpacyStopwordRemover, BobcatParser\n",
        "import csv\n",
        "\n",
        "# Inițializează instrumentele de procesare\n",
        "tokeniser = SpacyTokeniser()\n",
        "lemmatizer = SpacyLemmatizer()\n",
        "stopword_remover = SpacyStopwordRemover()\n",
        "\n",
        "# Exemplu de articole (înlocuiește cu datele tale din CSV)\n",
        "articles = [\n",
        "    \"Quantum computing is a revolutionary field in technology.\",\n",
        "    \"The future of artificial intelligence is uncertain.\"\n",
        "]\n",
        "\n",
        "# Deschide un fișier CSV pentru a salva rezultatele\n",
        "with open('quantum_processed_articles.csv', mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Article', 'Tokens', 'Lemmatized Tokens', 'Stopwords Removed', 'Processed Article'])  # Header\n",
        "\n",
        "    for article in articles:\n",
        "        # Tokenizarea propoziției\n",
        "        tokens = tokeniser.tokenise_sentence(article)\n",
        "\n",
        "        # Lematizarea tokenurilor\n",
        "        lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "\n",
        "        # Eliminarea cuvintelor de oprire\n",
        "        filtered_tokens = [token for token in lemmatized_tokens if not stopword_remover.is_stopword(token)]\n",
        "\n",
        "        # Reconstructia articolului după eliminarea stopword-urilor\n",
        "        processed_article = ' '.join(filtered_tokens)\n",
        "\n",
        "        # Salvează articolul, tokenurile, tokenurile lematizate, cuvintele fără stopwords și articolul procesat\n",
        "        writer.writerow([article, tokens, lemmatized_tokens, filtered_tokens, processed_article])  # Salvează și articolul procesat\n",
        "\n",
        "print(\"Procesare finalizată, rezultatele sunt salvate în 'quantum_processed_articles.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08K-YfLsO_yM",
        "outputId": "951297ac-5053-406e-ced6-851af1a737d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, autoray, nvidia-cusparse-cu12, nvidia-cudnn-cu12, diastatic-malt, nvidia-cusolver-cu12, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ],
      "source": [
        "pip install pennylane torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "WCogpsxgPEWL",
        "outputId": "4d4a669e-9596-4e6e-adf4-da2f7a031f56"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-de2c1ba8a0d5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpennylane\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mqml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpairwise\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   2149\u001b[0m )\n\u001b[1;32m   2150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2151\u001b[0;31m from torch import (\n\u001b[0m\u001b[1;32m   2152\u001b[0m     \u001b[0m__config__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__config__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2153\u001b[0m     \u001b[0m__future__\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__future__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nested/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Allowlist these for weights_only load of NJT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested_tensor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNestedTensor\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_NestedTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rebuild_njt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserialization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_safe_globals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_NestedTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_rebuild_njt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nested/_internal/nested_tensor.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDispatchKey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDispatchKeySet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prims_common\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_expandable_to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnested_int\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNestedIntNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweak\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWeakTensorKeyDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nested/_internal/nested_int.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constant_symnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstantIntNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     85\u001b[0m '''\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m from torch.fx._symbolic_trace import (  # noqa: F401\n\u001b[0m\u001b[1;32m     88\u001b[0m     \u001b[0mPH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mProxyableClassMeta\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/_symbolic_trace.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_lazy_graph_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_make_graph_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_PyTreeCodeGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PyTreeInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGraphModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/_lazy_graph_module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcontextmanager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from torch.fx.graph_module import (\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0m_format_import_block\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mGraphModule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_custom_builtins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_is_from_torch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_PyTreeCodeGen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPythonCode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/graph.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_pytree\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfx_pytree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_compatibility\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_get_qualified_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_type_repr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mArgument\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/fx/node.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_async\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m     \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_async\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m     \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_scalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maten\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_tensor_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, op_name)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m             \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualified_op_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 raise AttributeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m_get_packet\u001b[0;34m(qualname, op_module)\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m     \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverload_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_get_operation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mop\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;31m# let the script frontend know that op is identical to the builtin op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Funcție pentru codificarea unui text într-un vector cuantic\n",
        "def quantum_text_embedding(text):\n",
        "    # Crează un circuit cuantic\n",
        "    dev = qml.device(\"default.qubit\", wires=2)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        # Codifică fiecare cuvânt în vectori cuantici\n",
        "        for word in text.split():\n",
        "            # Pentru fiecare cuvânt, aplici un operator cuantic (de exemplu, rotiri)\n",
        "            qml.Hadamard(wires=0)  # Exemplu simplu, poți extinde aici\n",
        "            qml.RX(np.pi/4, wires=1)\n",
        "        return qml.probs(wires=[0, 1])\n",
        "\n",
        "    return circuit()\n",
        "\n",
        "# Funcție pentru calcularea similarității dintre două texte\n",
        "def quantum_similarity(text1, text2):\n",
        "    # Codifică ambele texte în vectori cuantici\n",
        "    embedding1 = quantum_text_embedding(text1)\n",
        "    embedding2 = quantum_text_embedding(text2)\n",
        "\n",
        "    # Convertește rezultatele cuantice într-o formă clasică pentru a calcula similaritatea\n",
        "    embedding1_classical = np.array(embedding1).real\n",
        "    embedding2_classical = np.array(embedding2).real\n",
        "\n",
        "    # Calculul similarității cosinusului între cele două texte\n",
        "    return cosine_similarity([embedding1_classical], [embedding2_classical])\n",
        "\n",
        "# Exemple de texte\n",
        "#text1 = \"Quantum computing is the future of technology.\" #Quantum Similarity:  0.6969234250586759\n",
        "text1= \"i feel sad\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Calcularea similarității\n",
        "similarity = quantum_similarity(text1, text2)\n",
        "print(\"Quantum Similarity: \", similarity[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDCevlxxaON7",
        "outputId": "b73715e0-6387-474d-9395-121cf0379a70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum Fidelity:  0.07322330470336286\n"
          ]
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Funcție pentru codificarea unui text într-un vector cuantic\n",
        "def quantum_text_embedding(text):\n",
        "    # Crează un circuit cuantic\n",
        "    dev = qml.device(\"default.qubit\", wires=2)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        # Codifică fiecare cuvânt în vectori cuantici\n",
        "        for word in text.split():\n",
        "            # Pentru fiecare cuvânt, aplici un operator cuantic (de exemplu, rotiri)\n",
        "            qml.Hadamard(wires=0)  # Exemplu simplu, poți extinde aici\n",
        "            qml.RX(np.pi/4, wires=1)\n",
        "        return qml.state()\n",
        "\n",
        "    return circuit()\n",
        "\n",
        "# Funcție pentru calcularea fidelității între două stări cuantice\n",
        "def quantum_fidelity(state1, state2):\n",
        "    # Calculează fidelitatea între două stări cuantice\n",
        "    # state1 = state1 / np.linalg.norm(state1)\n",
        "    # state2 = state2 / np.linalg.norm(state2)\n",
        "    overlap = np.abs(np.dot(state1, state2))**2\n",
        "    return overlap\n",
        "\n",
        "# Funcție pentru calcularea similarității dintre două texte\n",
        "def quantum_similarity(text1, text2):\n",
        "    # Codifică ambele texte în vectori cuantici\n",
        "    embedding1 = quantum_text_embedding(text1)\n",
        "    embedding2 = quantum_text_embedding(text2)\n",
        "\n",
        "    # Calculăm fidelitatea între cele două stări cuantice\n",
        "    fidelity = quantum_fidelity(embedding1, embedding2)\n",
        "\n",
        "    return fidelity\n",
        "\n",
        "# Exemple de texte\n",
        "#text1 = \"Quantum computing is the future of technology.\"#Quantum Fidelity:  0.4267766952966355\n",
        "text1 = \"i feel sad\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Calcularea similarității\n",
        "similarity = quantum_similarity(text1, text2)\n",
        "print(\"Quantum Fidelity: \", similarity)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnSDvvFEbnir",
        "outputId": "73a66203-411a-4a20-cb18-6ea03c2b08ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity (TF-IDF): 0.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Exemple de texte\n",
        "text1 = \"i feel sad.\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Aplicăm TF-IDF pentru a transforma textele în vectori\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
        "\n",
        "# Calculăm similaritatea cosinus între cele două texte\n",
        "similarity_tfidf = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])\n",
        "print(f\"Cosine Similarity (TF-IDF): {similarity_tfidf[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MQofyuubrWS",
        "outputId": "89db42c8-b07a-4b2a-f517-7ab214b8e7d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity (BERT): 0.39870601892471313\n"
          ]
        }
      ],
      "source": [
        "from transformers import BertModel, BertTokenizer\n",
        "import torch\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Încarcă modelul BERT pre-antrenat și tokenizer-ul\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Funcție pentru a obține embeddings de la BERT\n",
        "def get_bert_embeddings(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
        "\n",
        "# Exemple de texte\n",
        "text1 = \"nothing.\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Obține embeddings pentru fiecare text\n",
        "embedding1 = get_bert_embeddings(text1)\n",
        "embedding2 = get_bert_embeddings(text2)\n",
        "\n",
        "# Calculăm similaritatea cosinus între embeddings\n",
        "similarity_bert = cosine_similarity([embedding1.numpy()], [embedding2.numpy()])\n",
        "print(f\"Cosine Similarity (BERT): {similarity_bert[0][0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnBBzigOe6t8",
        "outputId": "c09cad99-778b-4eea-f8e2-5d969fab3e02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantum Similarity:  1.0000000000000002\n"
          ]
        }
      ],
      "source": [
        "import pennylane as qml\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Creăm un dispozitiv cuantic\n",
        "dev = qml.device(\"default.qubit\", wires=4)  # folosim 4 qubiți pentru a reprezenta cuvintele din text\n",
        "\n",
        "# Funcție pentru codificarea unui cuvânt într-un embedding cuantic\n",
        "def quantum_embedding(word):\n",
        "    # Folosim un circuit cuantic pentru a genera un embedding cuantic\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        # Codificăm cuvântul printr-un set de operații cuantice\n",
        "        qml.Hadamard(wires=0)\n",
        "        qml.RX(np.pi / 4, wires=1)\n",
        "        qml.RY(np.pi / 2, wires=2)\n",
        "        qml.RZ(np.pi / 3, wires=3)\n",
        "        return qml.state()\n",
        "\n",
        "    # Executăm circuitul pentru a obține starea cuantică\n",
        "    state = circuit()\n",
        "    # Returnăm doar partea reală a stării cuantice\n",
        "    return np.real(state)\n",
        "\n",
        "# Funcție pentru calcularea similarității cosinus între două embedding-uri cuantice\n",
        "def quantum_similarity(embedding1, embedding2):\n",
        "    # Calculăm similaritatea cosinus între cele două embedding-uri\n",
        "    return cosine_similarity([embedding1], [embedding2])\n",
        "\n",
        "# Funcție pentru a codifica un text întreg într-un set de embedding-uri cuantice\n",
        "def encode_text(text):\n",
        "    # Împărțim textul în cuvinte și generăm embedding-uri cuantice pentru fiecare cuvânt\n",
        "    words = text.split()\n",
        "    embeddings = [quantum_embedding(word) for word in words]\n",
        "    return embeddings\n",
        "\n",
        "# Exemplu de texte\n",
        "text1 = \"i feel sad today.\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Codificăm textele în embedding-uri cuantice\n",
        "embeddings1 = encode_text(text1)\n",
        "embeddings2 = encode_text(text2)\n",
        "\n",
        "# Calculăm similaritatea între embedding-urile cuantice\n",
        "similarity = quantum_similarity(np.mean(embeddings1, axis=0), np.mean(embeddings2, axis=0))\n",
        "\n",
        "print(\"Quantum Similarity: \", similarity[0][0])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xfASX13S1J6"
      },
      "outputs": [],
      "source": [
        "pip install lambeq[extras]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMGjWZD2THhI"
      },
      "outputs": [],
      "source": [
        "pip install lambeq[experimental]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "SngnrWeiQStg",
        "outputId": "822cdc7b-608e-4d9c-81ba-522c5183f19a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Diagram(dom=Ty(), cod=Ty(qubit), layers=[Layer(left=Ty(), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(), box=[CRz(Quantum__n@n.l_0); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit), box=[Rx(computing__n_0); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit), box=[Rz(computing__n_1); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit), box=[Rx(computing__n_2); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit), box=[CRz(is__n.r@s@n.l_0); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[CRz(is__n.r@s@n.l_1); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[CRz(the__n@n.l_0); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rx(future__n_0); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rz(future__n_1); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rx(future__n_2); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[CRz(of__n.r@n@n.l_0); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[CRz(of__n.r@n@n.l_1); Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty() -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rx(technology.__n_0); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rz(technology.__n_1); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[Rx(technology.__n_2); Ty(qubit) -> Ty(qubit)], right=Ty()), Layer(left=Ty(qubit), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit @ qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit @ qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty()), Layer(left=Ty(qubit @ qubit @ qubit), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit @ qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit)), Layer(left=Ty(qubit @ qubit @ qubit), box=[0; Ty(qubit) -> Ty()], right=Ty()), Layer(left=Ty(), box=[CX; Ty(qubit @ qubit) -> Ty(qubit @ qubit)], right=Ty(qubit)), Layer(left=Ty(), box=[H; Ty(qubit) -> Ty(qubit)], right=Ty(qubit @ qubit)), Layer(left=Ty(qubit), box=Sqrt(name='√(2)', dom=Ty(), cod=Ty(), z=0, data=2, is_mixed=False, self_adjoint=False, __hash__=<function Box.__hash__ at 0x796d45fcfe20>), right=Ty(qubit @ qubit)), Layer(left=Ty(), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit @ qubit)), Layer(left=Ty(), box=[0; Ty(qubit) -> Ty()], right=Ty(qubit))], __hash__=<function Diagram.__hash__ at 0x796d4fcf51b0>)\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'quantum_vector1' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-040ee931bdb4>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Calculăm similaritatea cosinus între cei doi vectori cuantici\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0msimilarity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquantum_vector1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mquantum_vector2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Afișăm similaritatea\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'quantum_vector1' is not defined"
          ]
        }
      ],
      "source": [
        "from lambeq import BobcatParser\n",
        "from lambeq import AtomicType, IQPAnsatz\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Creează un parser cu Bobcat\n",
        "parser = BobcatParser()\n",
        "\n",
        "# Definește cele două propoziții\n",
        "text1 = \"Quantum computing is the future of technology.\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Transformăm propozițiile în diagrame cuantice folosind BobcatParser\n",
        "diagram1 = parser.sentence2diagram(text1)\n",
        "diagram2 = parser.sentence2diagram(text2)\n",
        "\n",
        "# Definirea ansatz-ului IQP\n",
        "ansatz = IQPAnsatz(\n",
        "    {AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},  # Tipurile atomice pentru propoziție\n",
        "    n_layers=1,  # 1 strat de qubiți\n",
        "    n_single_qubit_params=3  # 3 parametri per qubit\n",
        ")\n",
        "\n",
        "# Aplicăm ansatz-ul IQP pe diagramele pentru fiecare propoziție\n",
        "train_circuit1 = ansatz((diagram1))\n",
        "train_circuit2 = ansatz((diagram2))\n",
        "print(train_circuit1)\n",
        "# Extragem stările cuantice pentru fiecare propoziție\n",
        "# quantum_state1 = train_circuit1.state()\n",
        "# quantum_state2 = train_circuit2.state()\n",
        "\n",
        "# Converim stările cuantice în vectori de amplitudini (real și imaginar)\n",
        "# quantum_vector1 = np.real(quantum_state1)\n",
        "# quantum_vector2 = np.real(quantum_state2)\n",
        "\n",
        "# Calculăm similaritatea cosinus între cei doi vectori cuantici\n",
        "similarity = cosine_similarity([quantum_vector1], [quantum_vector2])\n",
        "\n",
        "# Afișăm similaritatea\n",
        "print(\"Quantum Similarity: \", similarity[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "UDyqYxk0WaSg",
        "outputId": "d21b190b-e6d6-4947-d0b3-087d6459267f"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Diagram' object has no attribute 'free_symbols'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-27d3c61426fe>\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Evaluăm circuitele folosind modelul NumpyModel (fără JIT pentru simplitate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlambeq\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumpyModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNumpyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_diagrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdiagram1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiagram2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_jit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Calculăm similaritatea cosinus între cei doi vectori de stare\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lambeq/training/model.py\u001b[0m in \u001b[0;36mfrom_diagrams\u001b[0;34m(cls, diagrams, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         model.symbols = sorted(\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcirc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiagrams\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_symbols\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             key=default_sort_key)\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lambeq/training/model.py\u001b[0m in \u001b[0;36m<setcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         model.symbols = sorted(\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0;34m{\u001b[0m\u001b[0msym\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcirc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiagrams\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msym\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcirc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_symbols\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             key=default_sort_key)\n\u001b[1;32m    183\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Diagram' object has no attribute 'free_symbols'"
          ]
        }
      ],
      "source": [
        "from lambeq import BobcatParser\n",
        "from lambeq import AtomicType, IQPAnsatz\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "\n",
        "# Creează un parser cu Bobcat\n",
        "parser = BobcatParser()\n",
        "\n",
        "# Definește cele două propoziții\n",
        "text1 = \"Quantum computing is the future of technology.\"\n",
        "text2 = \"The field of quantum computing is rapidly evolving.\"\n",
        "\n",
        "# Transformăm propozițiile în diagrame cuantice folosind BobcatParser\n",
        "diagram1 = parser.sentence2diagram(text1)\n",
        "diagram2 = parser.sentence2diagram(text2)\n",
        "\n",
        "# Definirea ansatz-ului IQP\n",
        "ansatz = IQPAnsatz(\n",
        "    {AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},  # Tipurile atomice pentru propoziție\n",
        "    n_layers=1,  # 1 strat de qubiți\n",
        "    n_single_qubit_params=3  # 3 parametri per qubit\n",
        ")\n",
        "\n",
        "# Aplicăm ansatz-ul IQP pe diagramele pentru fiecare propoziție\n",
        "train_circuit1 = ansatz((diagram1))\n",
        "train_circuit2 = ansatz((diagram2))\n",
        "\n",
        "# Evaluăm circuitele folosind modelul NumpyModel (fără JIT pentru simplitate)\n",
        "from lambeq import NumpyModel\n",
        "model = NumpyModel.from_diagrams([diagram1, diagram2], use_jit=False)\n",
        "print(model)\n",
        "# Calculăm similaritatea cosinus între cei doi vectori de stare\n",
        "#similarity = cosine_similarity([result1], [result2])\n",
        "\n",
        "#print(\"Similaritatea cosinus între propoziții:\", similarity[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gu9If-YhZEGU"
      },
      "outputs": [],
      "source": [
        "from lambeq import AtomicType, BobcatParser, TensorAnsatz\n",
        "from lambeq.backend.tensor import Dim\n",
        "\n",
        "parser = BobcatParser()\n",
        "pregroup_diagram = parser.sentence2diagram('This is a tensor network.')\n",
        "\n",
        "ansatz = TensorAnsatz({AtomicType.NOUN: Dim(2), AtomicType.SENTENCE: Dim(4)})\n",
        "tensor_diagram = ansatz(pregroup_diagram)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A128gwqUZGqW"
      },
      "outputs": [],
      "source": [
        "from lambeq import PytorchModel\n",
        "\n",
        "model = PytorchModel.from_diagrams([tensor_diagram])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "sCBC1kUlZS8D",
        "outputId": "713e08da-7cb3-433a-a016-39c92e8af6b8"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'Layer' object has no attribute 'boxes'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-88861bc3aaee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_diagram_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_diagram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lambeq/training/pytorch_model.py\u001b[0m in \u001b[0;36mget_diagram_output\u001b[0;34m(self, diagrams)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mdiagrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiagrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# deepcopy, but faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdiagram\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiagrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdiagram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboxes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSymbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Layer' object has no attribute 'boxes'"
          ]
        }
      ],
      "source": [
        "print(model.get_diagram_output(diagrams=list(tensor_diagram)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZC-8mloINKc",
        "outputId": "3abe0d3c-d7c6-4a99-c87a-45d1b6e635e5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0n2_x4_iFGX0",
        "outputId": "3e0b16aa-f045-465a-d109-e3ce05d7ee53"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed summaries saved to 'processed_summaries.csv'\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "# Load the spaCy lemmatization model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text.lower())  # tokenize and convert to lowercase\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]\n",
        "\n",
        "    # Stemming (optional, but may improve performance in some cases)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "    # Lemmatize with spaCy\n",
        "    doc = nlp(\" \".join(stemmed_words))\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "\n",
        "    # Return the processed text\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "df = pd.read_csv(input_file, usecols=[\"Index\", \"Summary\"])\n",
        "\n",
        "# Create a dictionary to store the index and processed summary\n",
        "processed_data = {}\n",
        "# Process each summary and store the results\n",
        "for index, row in df.iterrows():\n",
        "    preprocessed_summary = preprocess_text(row[\"Summary\"])\n",
        "    processed_data[row[\"Index\"]] = preprocessed_summary\n",
        "\n",
        "# Process each summary and store the results\n",
        "for index, row in df.iterrows():\n",
        "    preprocessed_summary = preprocess_text(row[\"Summary\"])\n",
        "    processed_data[row[\"Index\"]] = preprocessed_summary\n",
        "\n",
        "# Convert processed data into a DataFrame\n",
        "processed_df = pd.DataFrame(list(processed_data.items()), columns=[\"Index\", \"Processed_Summary\"])\n",
        "\n",
        "# Save the processed data to a new CSV\n",
        "processed_df.to_csv(\"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries.csv\", index=False)\n",
        "\n",
        "print(\"Processed summaries saved to 'processed_summaries.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kM-bPSDLMUy6"
      },
      "outputs": [],
      "source": [
        "pip install pennylane torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKqT98hMMPgK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Load the lemmatized CSV\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Quantum feature map function\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Function to compute quantum similarity\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "    quantum_real_parts = [np.real(state) for state in quantum_states]\n",
        "    similarities = cosine_similarity(quantum_real_parts)\n",
        "    return similarities\n",
        "\n",
        "# Step 1: Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "n_components = 6  # Matches number of qubits\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Step 3: Compute quantum similarity\n",
        "similarity_matrix = quantum_similarity(reduced_matrix)\n",
        "\n",
        "# Step 4: Find top 5 similar entries for each index\n",
        "top_similarities = {}\n",
        "for i, row in df.iterrows():\n",
        "    similarities = similarity_matrix[i]\n",
        "    top_5_indices = np.argsort(similarities)[-6:-1][::-1]  # Top 5, excluding self\n",
        "    top_similarities[row[\"Index\"]] = top_5_indices\n",
        "\n",
        "# # Step 5: Save results to CSV\n",
        "# output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/top_similarities_q_s_15_qubiti.csv\"\n",
        "# similarities_df = pd.DataFrame.from_dict(top_similarities, orient=\"index\", columns=[\"Top1\", \"Top2\", \"Top3\", \"Top4\", \"Top5\"])\n",
        "# similarities_df.index.name = \"Index\"\n",
        "# similarities_df.to_csv(output_file)\n",
        "\n",
        "# print(\"Top 5 similarities saved to:\", output_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8KEfW4mYiHk",
        "outputId": "e5337e90-ec39-4adf-bb1b-a2112a5e749a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.         0.84550964 0.94878695 ... 0.83065705 0.77475513 0.7968862 ]\n",
            " [0.84550964 1.         0.9239266  ... 0.91289922 0.91424548 0.91703804]\n",
            " [0.94878695 0.9239266  1.         ... 0.88656132 0.87076831 0.89606478]\n",
            " ...\n",
            " [0.83065705 0.91289922 0.88656132 ... 1.         0.95537217 0.94147839]\n",
            " [0.77475513 0.91424548 0.87076831 ... 0.95537217 1.         0.98099507]\n",
            " [0.7968862  0.91703804 0.89606478 ... 0.94147839 0.98099507 1.        ]]\n"
          ]
        }
      ],
      "source": [
        "print(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eirPDOwBYxXZ",
        "outputId": "9f926069-5c12-45d4-f9dc-38bb55ac9aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(490, 490)\n"
          ]
        }
      ],
      "source": [
        "print(similarity_matrix.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRMpVPmvaVpA",
        "outputId": "2928efd7-eb2a-435b-f767-57748de17c43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((490, 490), True)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def check_matrix_symmetry(matrix):\n",
        "    shape = matrix.shape\n",
        "    symmetric = np.allclose(matrix, matrix.T)\n",
        "    return shape, symmetric\n",
        "check_matrix_symmetry(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HJ7hGOOa7kb",
        "outputId": "e8ece06d-f671-4013-b300-17f3c4d38128"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum value: 0.6857535922840451\n",
            "Index of minimum value: (17, 478)\n"
          ]
        }
      ],
      "source": [
        "def find_min_value_and_index(matrix):\n",
        "    min_value = np.min(matrix)\n",
        "    min_index = np.unravel_index(np.argmin(matrix), matrix.shape)  # Get row and column index\n",
        "    return min_value, min_index\n",
        "min_value, min_index = find_min_value_and_index(similarity_matrix)\n",
        "print(\"Minimum value:\", min_value)\n",
        "print(\"Index of minimum value:\", min_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh3IRqW9jY6X",
        "outputId": "2e398820-965c-47f4-88d9-917fd212abb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top 5 similarities saved to: /content/drive/MyDrive/QuantumElearningDataSet/top_similarities_title.csv\n"
          ]
        }
      ],
      "source": [
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "top_similarities = {}\n",
        "for i, row in df.iterrows():\n",
        "    similarities = similarity_matrix[i]\n",
        "    top_5_indices = np.argsort(similarities)[-6:-1][::-1]  # Top 5, excluding self\n",
        "\n",
        "    # Collecting the top 5 similar articles with their similarity percentages\n",
        "    top_5_info = []\n",
        "    for idx in top_5_indices:\n",
        "        title = df.iloc[idx][\"Title\"]\n",
        "        similarity_percentage = similarities[idx] * 100  # Convert to percentage\n",
        "        top_5_info.append(f\"{df.iloc[idx]['Index']} - {title} - {similarity_percentage:.2f}%\")\n",
        "\n",
        "    top_similarities[row[\"Index\"]] = top_5_info\n",
        "\n",
        "# Step 5: Prepare data for CSV (including index and title)\n",
        "final_data = []\n",
        "for index, top_articles in top_similarities.items():\n",
        "    # The first column will contain index and title of the current article\n",
        "    current_title = df.loc[df[\"Index\"] == index, \"Title\"].values[0]\n",
        "    row_data = [f\"{index} - {current_title}\"]  # Start with index and title\n",
        "\n",
        "    # Add the top 5 similar articles with their details\n",
        "    row_data.extend(top_articles)\n",
        "    final_data.append(row_data)\n",
        "\n",
        "# Convert to DataFrame\n",
        "columns = [\"Index and Title\", \"Top1\", \"Top2\", \"Top3\", \"Top4\", \"Top5\"]\n",
        "similarities_df = pd.DataFrame(final_data, columns=columns)\n",
        "\n",
        "# Step 6: Save results to CSV\n",
        "output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/top_similarities_title.csv\"\n",
        "similarities_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"Top 5 similarities saved to:\", output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEfisjWemjKX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "csv_path = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df[\"category\"] = \"quantum\"\n",
        "\n",
        "df.to_csv(csv_path, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWA5KfXYp8Bg",
        "outputId": "e5c55098-815e-4c4e-bba7-1488d780fdb4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24 articole despre social science au fost adăugate cu succes!\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import xml.etree.ElementTree as ET\n",
        "import pandas as pd\n",
        "import io\n",
        "from PyPDF2 import PdfReader\n",
        "\n",
        "# Calea către CSV existent\n",
        "csv_path = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "# Funcție pentru a descărca și extrage text din PDF\n",
        "def download_pdf_and_extract_text(pdf_url):\n",
        "    try:\n",
        "        response = requests.get(pdf_url)\n",
        "        if response.status_code == 200:\n",
        "            pdf_file = io.BytesIO(response.content)\n",
        "            pdf_reader = PdfReader(pdf_file)\n",
        "            text = \"\\n\".join([page.extract_text() for page in pdf_reader.pages if page.extract_text()])\n",
        "            return text.strip() if text else \"No text extracted\"\n",
        "        else:\n",
        "            return \"Failed to download PDF\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Funcție pentru a lua articolele de pe arXiv\n",
        "def fetch_arxiv_data():\n",
        "    url = \"http://export.arxiv.org/api/query\"\n",
        "    params = {\n",
        "        \"search_query\": \"all:social science\",\n",
        "        \"start\": 0,\n",
        "        \"max_results\": 24\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Eroare la API: {response.status_code}\")\n",
        "        return\n",
        "\n",
        "    # Parsează XML-ul\n",
        "    root = ET.fromstring(response.text)\n",
        "    ns = {'arxiv': 'http://www.w3.org/2005/Atom'}\n",
        "\n",
        "    dataset = []\n",
        "\n",
        "    # Iterăm prin rezultate\n",
        "    for i, entry in enumerate(root.findall('arxiv:entry', ns)):\n",
        "        title = entry.find('arxiv:title', ns).text.strip()\n",
        "        authors = \", \".join(author.find('arxiv:name', ns).text for author in entry.findall('arxiv:author', ns))\n",
        "        published = entry.find('arxiv:published', ns).text\n",
        "        summary = entry.find('arxiv:summary', ns).text.strip()\n",
        "\n",
        "        # Găsim link-ul către PDF\n",
        "        pdf_link = entry.find('.//arxiv:link[@title=\"pdf\"]', ns)\n",
        "        pdf_url = pdf_link.attrib['href'] if pdf_link is not None else None\n",
        "\n",
        "        # Descărcăm și extragem textul din PDF (dacă există link)\n",
        "        pdf_text = download_pdf_and_extract_text(pdf_url) if pdf_url else \"No PDF available\"\n",
        "\n",
        "        # Adăugăm articolul în dataset\n",
        "        dataset.append({\n",
        "            \"Index\": 467 + i,\n",
        "            \"Title\": title,\n",
        "            \"Authors\": authors,\n",
        "            \"Published\": published,\n",
        "            \"Summary\": summary,\n",
        "            \"PDF_Content\": pdf_text,\n",
        "            \"Category\": \"social science\"\n",
        "        })\n",
        "\n",
        "    return dataset\n",
        "\n",
        "new_data = fetch_arxiv_data()\n",
        "\n",
        "df_new = pd.DataFrame(new_data)\n",
        "\n",
        "df_existing = pd.read_csv(csv_path)\n",
        "\n",
        "df_final = pd.concat([df_existing, df_new], ignore_index=True)\n",
        "\n",
        "df_final.to_csv(csv_path, index=False)\n",
        "\n",
        "print(\"24 articole despre social science au fost adăugate cu succes!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP6nfgMGskE0",
        "outputId": "7879f104-df36-44a2-fa67-445380bbce4d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processed summaries saved to 'processed_summaries_q_s.csv'\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import spacy\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "# Download necessary NLTK resources\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('punkt_tab')\n",
        "# Load the spaCy lemmatization model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "# Function to preprocess the text\n",
        "def preprocess_text(text):\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    # Tokenize the text\n",
        "    words = word_tokenize(text.lower())  # tokenize and convert to lowercase\n",
        "\n",
        "    # Remove stop words\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_words = [word for word in words if word not in stop_words and word.isalpha()]\n",
        "\n",
        "    # Stemming (optional, but may improve performance in some cases)\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(word) for word in filtered_words]\n",
        "\n",
        "    # Lemmatize with spaCy\n",
        "    doc = nlp(\" \".join(stemmed_words))\n",
        "    lemmatized_words = [token.lemma_ for token in doc]\n",
        "\n",
        "    # Return the processed text\n",
        "    return \" \".join(lemmatized_words)\n",
        "\n",
        "# Read the CSV file\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "df = pd.read_csv(input_file, usecols=[\"Index\", \"Summary\"])\n",
        "\n",
        "# Create a dictionary to store the index and processed summary\n",
        "processed_data = {}\n",
        "# Process each summary and store the results\n",
        "for index, row in df.iterrows():\n",
        "    preprocessed_summary = preprocess_text(row[\"Summary\"])\n",
        "    processed_data[row[\"Index\"]] = preprocessed_summary\n",
        "\n",
        "# Process each summary and store the results\n",
        "for index, row in df.iterrows():\n",
        "    preprocessed_summary = preprocess_text(row[\"Summary\"])\n",
        "    processed_data[row[\"Index\"]] = preprocessed_summary\n",
        "\n",
        "# Convert processed data into a DataFrame\n",
        "processed_df = pd.DataFrame(list(processed_data.items()), columns=[\"Index\", \"Processed_Summary\"])\n",
        "\n",
        "# Save the processed data to a new CSV\n",
        "processed_df.to_csv(\"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\", index=False)\n",
        "\n",
        "print(\"Processed summaries saved to 'processed_summaries_q_s.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bj0Y9ONHwzbw",
        "outputId": "defb7913-3e42-458e-cf09-6be1dc55755d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⚠️ Diferență de categorie! Index 468 (Artificiality in Social Sciences - social science) vs Index 71 (Quantum computation and complexity theory - quantum)\n",
            "⚠️ Diferență de categorie! Index 468 (Artificiality in Social Sciences - social science) vs Index 312 (Finding the Optimal Currency Composition of Foreign Exchange Reserves\n",
            "  with a Quantum Computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 468 (Artificiality in Social Sciences - social science) vs Index 216 (Low-temperature environments for quantum computation and quantum\n",
            "  simulation - quantum)\n",
            "⚠️ Diferență de categorie! Index 469 (The Influence of Social Networks on Human Society - social science) vs Index 332 (Universe as quantum computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 469 (The Influence of Social Networks on Human Society - social science) vs Index 314 (Towards Energetic Quantum Advantage in Trapped-Ion Quantum Computation - quantum)\n",
            "⚠️ Diferență de categorie! Index 470 (Towards the social media studies of science: social media metrics,\n",
            "  present and future - social science) vs Index 302 (Quantum Internet: from Communication to Distributed Computing! - quantum)\n",
            "⚠️ Diferență de categorie! Index 470 (Towards the social media studies of science: social media metrics,\n",
            "  present and future - social science) vs Index 34 (Quantum computer for dummies (in Russian) - quantum)\n",
            "⚠️ Diferență de categorie! Index 470 (Towards the social media studies of science: social media metrics,\n",
            "  present and future - social science) vs Index 121 (Theoretical issues in spin-based quantum dot quantum computation - quantum)\n",
            "⚠️ Diferență de categorie! Index 471 (AI for social science and social science of AI: A Survey - social science) vs Index 151 (The lambda-q calculus can efficiently simulate quantum computers - quantum)\n",
            "⚠️ Diferență de categorie! Index 471 (AI for social science and social science of AI: A Survey - social science) vs Index 336 (Computational depth complexity of measurement-based quantum computation - quantum)\n",
            "⚠️ Diferență de categorie! Index 472 (Analysis and Predictions of Social Phenomena via social media using\n",
            "  Social Physics method - social science) vs Index 401 (Using Quantum Computers for Quantum Simulation - quantum)\n",
            "⚠️ Diferență de categorie! Index 472 (Analysis and Predictions of Social Phenomena via social media using\n",
            "  Social Physics method - social science) vs Index 298 (An optically driven quantum dot quantum computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 473 (Two Types of Social Grooming Methods depending on the Trade-off between\n",
            "  the Number and Strength of Social Relationships - social science) vs Index 341 (Space-Efficient Error Reduction for Unitary Quantum Computations - quantum)\n",
            "⚠️ Diferență de categorie! Index 475 (How Far Can We Go Through Social System?: Algorithmic Information Social\n",
            "  Theories - social science) vs Index 391 (Introduction to the multiple-quantum operator spaces - quantum)\n",
            "⚠️ Diferență de categorie! Index 475 (How Far Can We Go Through Social System?: Algorithmic Information Social\n",
            "  Theories - social science) vs Index 63 (Accelerated Quantum Amplitude Estimation without QFT - quantum)\n",
            "⚠️ Diferență de categorie! Index 475 (How Far Can We Go Through Social System?: Algorithmic Information Social\n",
            "  Theories - social science) vs Index 212 (Cryptography, Quantum Computation and Trapped Ions - quantum)\n",
            "⚠️ Diferență de categorie! Index 475 (How Far Can We Go Through Social System?: Algorithmic Information Social\n",
            "  Theories - social science) vs Index 441 (Teaching quantum information technologies and a practical module for\n",
            "  online and offline undergraduate students - quantum)\n",
            "⚠️ Diferență de categorie! Index 476 (Social Media as Windows on the Social Life of the Mind - social science) vs Index 147 (The unity between quantum field computation, real computation, and\n",
            "  quantum computation - quantum)\n",
            "⚠️ Diferență de categorie! Index 478 (Social Expansion versus Social Fragmentation - social science) vs Index 204 (Lecture notes on quantum computing - quantum)\n",
            "⚠️ Diferență de categorie! Index 478 (Social Expansion versus Social Fragmentation - social science) vs Index 251 (Inclusive learning for quantum computing: supporting the aims of quantum\n",
            "  literacy using the puzzle game Quantum Odyssey - quantum)\n",
            "⚠️ Diferență de categorie! Index 478 (Social Expansion versus Social Fragmentation - social science) vs Index 449 (Investigating how to simulate lattice gauge theories on a quantum\n",
            "  computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 480 (Generative AI has lowered the barriers to computational social sciences - social science) vs Index 98 (Quantum Reservoir Computing Implementations for Classical and Quantum\n",
            "  Problems - quantum)\n",
            "⚠️ Diferență de categorie! Index 480 (Generative AI has lowered the barriers to computational social sciences - social science) vs Index 180 (Quantum Consensus: an overview - quantum)\n",
            "⚠️ Diferență de categorie! Index 480 (Generative AI has lowered the barriers to computational social sciences - social science) vs Index 161 (Robust Fitting on a Gate Quantum Computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 482 (Data-driven Computational Social Science: A Survey - social science) vs Index 244 (Equal cost of computation for truth and falsity of experimental quantum\n",
            "  propositions necessitates quantum parallel computing - quantum)\n",
            "⚠️ Diferență de categorie! Index 482 (Data-driven Computational Social Science: A Survey - social science) vs Index 32 (Quantum computer and its quasiclassical model - quantum)\n",
            "⚠️ Diferență de categorie! Index 482 (Data-driven Computational Social Science: A Survey - social science) vs Index 48 (Understanding Quantum Technologies 2024 - quantum)\n",
            "⚠️ Diferență de categorie! Index 483 (Emergence of economic and social disparities through competitive\n",
            "  gift-giving - social science) vs Index 377 (A Physics Lab Inside Your Head: Quantum Thought Experiments as an\n",
            "  Educational Tool - quantum)\n",
            "⚠️ Diferență de categorie! Index 483 (Emergence of economic and social disparities through competitive\n",
            "  gift-giving - social science) vs Index 445 (Quantum Tetrahedra - quantum)\n",
            "⚠️ Diferență de categorie! Index 485 (On the Representation and Construction of Equitable Social Welfare\n",
            "  Orders - social science) vs Index 439 (Quantum buses and quantum computer architecture based on quantum dots - quantum)\n",
            "⚠️ Diferență de categorie! Index 485 (On the Representation and Construction of Equitable Social Welfare\n",
            "  Orders - social science) vs Index 283 (DisQ: A Novel Quantum Output State Classification Method on IBM Quantum\n",
            "  Computers using OpenPulse - quantum)\n",
            "⚠️ Diferență de categorie! Index 486 (Modeling and analysis of social phenomena: challenges and possible\n",
            "  research directions - social science) vs Index 460 (Quantum computing at the quantum advantage threshold: a down-to-business\n",
            "  review - quantum)\n",
            "⚠️ Diferență de categorie! Index 486 (Modeling and analysis of social phenomena: challenges and possible\n",
            "  research directions - social science) vs Index 231 (Quantum Computers: Engines for Next Industrial Revolution - quantum)\n",
            "⚠️ Diferență de categorie! Index 488 (Characterizing SW-Efficiency in the Social Choice Domain - social science) vs Index 290 (Quantum circuit optimization for unitary operators over non-adjacent\n",
            "  qudits - quantum)\n",
            "⚠️ Diferență de categorie! Index 488 (Characterizing SW-Efficiency in the Social Choice Domain - social science) vs Index 442 (Teleportation as a quantum computation - quantum)\n",
            "⚠️ Diferență de categorie! Index 488 (Characterizing SW-Efficiency in the Social Choice Domain - social science) vs Index 298 (An optically driven quantum dot quantum computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 488 (Characterizing SW-Efficiency in the Social Choice Domain - social science) vs Index 201 (Quantum Computing Education for Computer Science Students: Bridging the\n",
            "  Gap with Layered Learning and Intuitive Analogies - quantum)\n",
            "⚠️ Diferență de categorie! Index 489 (Global AI Ethics: A Review of the Social Impacts and Ethical\n",
            "  Implications of Artificial Intelligence - social science) vs Index 299 (Searching with Quantum Computers - quantum)\n",
            "⚠️ Diferență de categorie! Index 489 (Global AI Ethics: A Review of the Social Impacts and Ethical\n",
            "  Implications of Artificial Intelligence - social science) vs Index 168 (Resource Allocation in Quantum Networks for Distributed Quantum\n",
            "  Computing - quantum)\n",
            "⚠️ Diferență de categorie! Index 489 (Global AI Ethics: A Review of the Social Impacts and Ethical\n",
            "  Implications of Artificial Intelligence - social science) vs Index 389 (Scalable cavity quantum electrodynamics system for quantum computing - quantum)\n",
            "⚠️ Diferență de categorie! Index 490 (Computer-Assisted Text Analysis for Social Science: Topic Models and\n",
            "  Beyond - social science) vs Index 378 (DisQ: A Model of Distributed Quantum Processors - quantum)\n",
            "⚠️ Diferență de categorie! Index 490 (Computer-Assisted Text Analysis for Social Science: Topic Models and\n",
            "  Beyond - social science) vs Index 162 (The Quantum Computer Puzzle (Expanded Version) - quantum)\n",
            "⚠️ Diferență de categorie! Index 490 (Computer-Assisted Text Analysis for Social Science: Topic Models and\n",
            "  Beyond - social science) vs Index 247 (Quantum Artificial Life in an IBM Quantum Computer - quantum)\n",
            "⚠️ Diferență de categorie! Index 490 (Computer-Assisted Text Analysis for Social Science: Topic Models and\n",
            "  Beyond - social science) vs Index 254 (Quantum Memory: A Missing Piece in Quantum Computing Units - quantum)\n",
            "✅ Top 5 similarități salvate în: /content/drive/MyDrive/QuantumElearningDataSet/top_fidelity_qml_formula_quantum_social_8_qubiti.csv\n",
            "Nr de articole cu diferite categorii: 44\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Calea către fișierul de intrare\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "# Citim datele\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Matricea de similaritate trebuie să fie deja definită\n",
        "# Exemplu: similarity_matrix = np.load(\"similarity_matrix.npy\")\n",
        "\n",
        "top_similarities = {}\n",
        "nr_diferente = 0\n",
        "for i, row in df.iterrows():\n",
        "    similarities = fidelity_matrix[i]\n",
        "    top_5_indices = np.argsort(similarities)[-6:-1][::-1]  # Top 5, excluzând self\n",
        "\n",
        "    # Informații pentru top 5 articole similare\n",
        "    top_5_info = []\n",
        "    current_category = df.iloc[i][\"Category\"]  # Categoria articolului curent\n",
        "\n",
        "    for idx in top_5_indices:\n",
        "        title = df.iloc[idx][\"Title\"]\n",
        "        category = df.iloc[idx][\"Category\"]\n",
        "        similarity_percentage = similarities[idx] * 100  # Convertit la procentaj\n",
        "\n",
        "        # Adăugăm categoria în informațiile articolului\n",
        "        top_5_info.append(f\"{df.iloc[idx]['Index']} - {title} - {category} - {similarity_percentage:.2f}%\")\n",
        "\n",
        "        # Verificăm dacă categoria diferă\n",
        "        if category != current_category:\n",
        "            nr_diferente += 1\n",
        "            print(f\"⚠️ Diferență de categorie! Index {row['Index']} ({row['Title']} - {current_category}) vs Index {df.iloc[idx]['Index']} ({title} - {category})\")\n",
        "\n",
        "    # Stocăm rezultatele\n",
        "    top_similarities[row[\"Index\"]] = top_5_info\n",
        "\n",
        "# Pregătim datele pentru CSV\n",
        "final_data = []\n",
        "\n",
        "for index, top_articles in top_similarities.items():\n",
        "    current_title = df.loc[df[\"Index\"] == index, \"Title\"].values[0]\n",
        "    current_category = df.loc[df[\"Index\"] == index, \"Category\"].values[0]\n",
        "\n",
        "    # Prima coloană: Index + Title + Category\n",
        "    row_data = [f\"{index} - {current_title} - {current_category}\"]\n",
        "\n",
        "    # Adăugăm top 5 articole similare\n",
        "    row_data.extend(top_articles)\n",
        "    final_data.append(row_data)\n",
        "\n",
        "# Convertim la DataFrame\n",
        "columns = [\"Index + Title + Category\", \"Top1\", \"Top2\", \"Top3\", \"Top4\", \"Top5\"]\n",
        "similarities_df = pd.DataFrame(final_data, columns=columns)\n",
        "\n",
        "# Salvăm în CSV\n",
        "output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/top_fidelity_qml_formula_quantum_social_8_qubiti.csv\"\n",
        "similarities_df.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"✅ Top 5 similarități salvate în:\", output_file)\n",
        "print(\"Nr de articole cu diferite categorii:\", nr_diferente)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDv1gAaJ1BZv",
        "outputId": "344237a0-e92f-4ca8-e123-8e7d9a95dc54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "           Category\n",
            "0           quantum\n",
            "1           quantum\n",
            "2           quantum\n",
            "3           quantum\n",
            "4           quantum\n",
            "..              ...\n",
            "485  social science\n",
            "486  social science\n",
            "487  social science\n",
            "488  social science\n",
            "489  social science\n",
            "\n",
            "[490 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "df = pd.read_csv(input_file, usecols=[\"Category\"])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgJuIu4a15I0",
        "outputId": "ebe2349f-5438-4b0d-afee-0f98c824e46b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Category\n",
            "0  quantum\n",
            "1  quantum\n",
            "2  quantum\n",
            "3  quantum\n",
            "4  quantum\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "# Citim fișierul\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Combinăm cele două coloane fără să pierdem date\n",
        "df[\"Category\"] = df[\"Category\"].fillna(df[\"category\"]) if \"category\" in df.columns else df[\"Category\"]\n",
        "df[\"Category\"] = df[\"category\"].fillna(df[\"Category\"]) if \"Category\" in df.columns else df[\"category\"]\n",
        "\n",
        "# Ștergem coloana redundantă (dacă există)\n",
        "df = df.drop(columns=[\"category\"], errors=\"ignore\")\n",
        "\n",
        "# Salvăm modificările (opțional)\n",
        "df.to_csv(input_file, index=False)\n",
        "\n",
        "# Verificăm primele rânduri\n",
        "print(df[[\"Category\"]].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-xNh6B-Gxyc",
        "outputId": "400c82a0-53d5-48f3-ebcd-f0bec1453fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting qiskit-ibm-provider\n",
            "  Downloading qiskit_ibm_provider-0.11.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: qiskit>=0.45.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (1.3.2)\n",
            "Requirement already satisfied: requests>=2.19 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (2.32.3)\n",
            "Collecting requests-ntlm>=1.1.0 (from qiskit-ibm-provider)\n",
            "  Downloading requests_ntlm-1.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy>=1.13 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (1.26.4)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (2.8.2)\n",
            "Requirement already satisfied: websocket-client>=1.5.1 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (1.8.0)\n",
            "Requirement already satisfied: websockets>=10.0 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (14.2)\n",
            "Requirement already satisfied: typing-extensions>=4.3 in /usr/local/lib/python3.11/dist-packages (from qiskit-ibm-provider) (4.12.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.0->qiskit-ibm-provider) (1.17.0)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (0.16.0)\n",
            "Requirement already satisfied: scipy>=1.5 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (1.13.1)\n",
            "Requirement already satisfied: sympy>=1.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (0.3.9)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (5.4.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in /usr/local/lib/python3.11/dist-packages (from qiskit>=0.45.0->qiskit-ibm-provider) (0.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-provider) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-provider) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19->qiskit-ibm-provider) (2024.12.14)\n",
            "Requirement already satisfied: cryptography>=1.3 in /usr/local/lib/python3.11/dist-packages (from requests-ntlm>=1.1.0->qiskit-ibm-provider) (43.0.3)\n",
            "Collecting pyspnego>=0.4.0 (from requests-ntlm>=1.1.0->qiskit-ibm-provider)\n",
            "  Downloading pyspnego-0.11.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-provider) (1.17.1)\n",
            "Requirement already satisfied: pbr>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from stevedore>=3.0.0->qiskit>=0.45.0->qiskit-ibm-provider) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.3->qiskit>=0.45.0->qiskit-ibm-provider) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography>=1.3->requests-ntlm>=1.1.0->qiskit-ibm-provider) (2.22)\n",
            "Downloading qiskit_ibm_provider-0.11.0-py3-none-any.whl (249 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.9/249.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests_ntlm-1.3.0-py3-none-any.whl (6.6 kB)\n",
            "Downloading pyspnego-0.11.2-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/130.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyspnego, requests-ntlm, qiskit-ibm-provider\n",
            "Successfully installed pyspnego-0.11.2 qiskit-ibm-provider-0.11.0 requests-ntlm-1.3.0\n"
          ]
        }
      ],
      "source": [
        "pip install qiskit-ibm-provider"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxYlwTBCGqUI",
        "outputId": "9cadf1e4-1410-4471-8620-438fb9ee3cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[<IBMBackend('ibm_brisbane')>, <IBMBackend('ibm_sherbrooke')>, <IBMBackend('ibm_kyiv')>]\n"
          ]
        }
      ],
      "source": [
        "from qiskit_ibm_provider import IBMProvider\n",
        "\n",
        "# Autentifică-te cu contul tău IBM Quantum\n",
        "provider = IBMProvider(token=\"bc1956aaf231d2374aee01a86837b733a7edad1f54d84e7c0d502a49625c4d9730d65bd47e4f487c14b354c6bd60d5a9b6989d1933ae495a1e8ea068823df2a9\")\n",
        "\n",
        "# Listează dispozitivele disponibile\n",
        "print(provider.backends())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiaPE0xIGn6",
        "outputId": "9e7f648e-fd2c-4023-a1f0-0336a0699428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ibm_brisbane  - Qubits: 127\n",
            "ibm_sherbrooke  - Qubits: 127\n",
            "ibm_kyiv  - Qubits: 127\n"
          ]
        }
      ],
      "source": [
        "for backend in provider.backends():\n",
        "    print(backend.name, \" - Qubits:\", backend.configuration().num_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QxbrE6MEJER1"
      },
      "outputs": [],
      "source": [
        "backend = provider.get_backend('ibm_kyiv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJEj8LN2NZRU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from qiskit import QuantumCircuit\n",
        "\n",
        "# Exemplu de funcție care creează o stare cuantică dintr-un vector\n",
        "def vector_to_quantum_state(vector):\n",
        "    # Normalizăm vectorul pentru a fi un vector de stare validă (norma 1)\n",
        "    norm_vector = vector / np.linalg.norm(vector)\n",
        "\n",
        "    # Creăm un circuit cu 127 qubiți (corespunzător dimensiunii tale)\n",
        "    n_qubits = 127\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "\n",
        "    # Mapăm valorile vectorului pe qubiți\n",
        "    for i in range(n_qubits):\n",
        "        # Aplicați un gate X pe qubitul i în funcție de valoarea din vector\n",
        "        if norm_vector[i] > 0:\n",
        "            qc.h(i)  # aplica Hadamard pentru a crea superpoziții\n",
        "        else:\n",
        "            qc.x(i)  # aplica X pentru a crea o stare negativă\n",
        "\n",
        "    return qc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TchIADSNgOw"
      },
      "outputs": [],
      "source": [
        "def quantum_distance(state_1, state_2, backend):\n",
        "    transpiled_state_1 = transpile(state_1, backend)\n",
        "    transpiled_state_2 = transpile(state_2, backend)\n",
        "\n",
        "    # Generăm și trimitem joburile pentru execuție\n",
        "    job_1 = backend.run(transpiled_state_1)\n",
        "    job_2 = backend.run(transpiled_state_2)\n",
        "\n",
        "    # Așteptăm rezultatele\n",
        "    result_1 = job_1.result()\n",
        "    result_2 = job_2.result()\n",
        "\n",
        "    # Obținem vectorii de stare\n",
        "    statevector_1 = result_1.get_statevector()\n",
        "    statevector_2 = result_2.get_statevector()\n",
        "\n",
        "    # Calculăm fidelitatea și distanța cuantică\n",
        "    fidelity = np.abs(np.dot(np.conj(statevector_1), statevector_2))**2\n",
        "    quantum_dist = 1 - fidelity\n",
        "    return quantum_dist\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Czy5VkclNyfz"
      },
      "outputs": [],
      "source": [
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Step 1: Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "n_components = 127  # Matches number of qubits\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "L83jwjYpNrpR",
        "outputId": "a3e34b04-f103-44c4-fbf4-081bd7f9a6a2"
      },
      "outputs": [
        {
          "ename": "IBMBackendApiError",
          "evalue": "'Error submitting job: \\'404 Client Error: Not Found for url: https://api.quantum.ibm.com/runtime/jobs. {\"errors\":[{\"code\":1211,\"message\":\"Program not found.\",\"solution\":\"Make sure you use a valid program name, such as \\\\\\'sampler\\\\\\' or \\\\\\'estimator\\\\\\'. Qiskit Runtime no longer supports the \\\\\\'backend.run\\\\\\' interface. Refer to the migration guide (https://docs.quantum.ibm.com/migration-guides/qiskit-runtime) for instructions to migrate to the primitives.\",\"more_info\":\"https://docs.quantum-computing.ibm.com/errors\"}]}\\''",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/api/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, bare, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: https://api.quantum.ibm.com/runtime/jobs",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRequestsApiError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/ibm_backend.py\u001b[0m in \u001b[0;36m_runtime_run\u001b[0;34m(self, program_id, inputs, backend_name, job_tags, image)\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             response = self.provider._runtime_client.program_run(\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mprogram_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogram_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/api/clients/runtime.py\u001b[0m in \u001b[0;36mprogram_run\u001b[0;34m(self, program_id, backend_name, params, image, hgp, log_level, session_id, job_tags, max_execution_time, session_time, start_session)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0mhgp_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"hub\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"group\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"project\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         return self._api.program_run(\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mprogram_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogram_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/api/rest/runtime.py\u001b[0m in \u001b[0;36mprogram_run\u001b[0;34m(self, program_id, backend_name, params, image, hub, group, project, log_level, session_id, job_tags, max_execution_time, session_time, start_session)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRuntimeEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 637\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/api/session.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, bare, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRequestsApiError\u001b[0m: '404 Client Error: Not Found for url: https://api.quantum.ibm.com/runtime/jobs. {\"errors\":[{\"code\":1211,\"message\":\"Program not found.\",\"solution\":\"Make sure you use a valid program name, such as \\'sampler\\' or \\'estimator\\'. Qiskit Runtime no longer supports the \\'backend.run\\' interface. Refer to the migration guide (https://docs.quantum.ibm.com/migration-guides/qiskit-runtime) for instructions to migrate to the primitives.\",\"more_info\":\"https://docs.quantum-computing.ibm.com/errors\"}]}'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mIBMBackendApiError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3c2453f74cbf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# Calculăm distanța cuantică\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mdistance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquantum_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# Completăm matricea de similaritate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-a9ef8e169e0c>\u001b[0m in \u001b[0;36mquantum_distance\u001b[0;34m(state_1, state_2, backend)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Generăm și trimitem joburile pentru execuție\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mjob_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspiled_state_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mjob_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspiled_state_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/ibm_backend.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, circuits, dynamic, job_tags, init_circuit, init_num_resets, header, shots, memory, meas_level, meas_return, rep_delay, init_qubits, use_measure_esp, noise_model, seed_simulator, **run_config)\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mrun_config_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"skip_transpilation\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 495\u001b[0;31m         return self._runtime_run(\n\u001b[0m\u001b[1;32m    496\u001b[0m             \u001b[0mprogram_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogram_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/qiskit_ibm_provider/ibm_backend.py\u001b[0m in \u001b[0;36m_runtime_run\u001b[0;34m(self, program_id, inputs, backend_name, job_tags, image)\u001b[0m\n\u001b[1;32m    530\u001b[0m             )\n\u001b[1;32m    531\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRequestsApiError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIBMBackendApiError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error submitting job: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             job = IBMCircuitJob(\n",
            "\u001b[0;31mIBMBackendApiError\u001b[0m: 'Error submitting job: \\'404 Client Error: Not Found for url: https://api.quantum.ibm.com/runtime/jobs. {\"errors\":[{\"code\":1211,\"message\":\"Program not found.\",\"solution\":\"Make sure you use a valid program name, such as \\\\\\'sampler\\\\\\' or \\\\\\'estimator\\\\\\'. Qiskit Runtime no longer supports the \\\\\\'backend.run\\\\\\' interface. Refer to the migration guide (https://docs.quantum.ibm.com/migration-guides/qiskit-runtime) for instructions to migrate to the primitives.\",\"more_info\":\"https://docs.quantum-computing.ibm.com/errors\"}]}\\''"
          ]
        }
      ],
      "source": [
        "similarity_matrix = np.zeros((len(reduced_matrix), len(reduced_matrix)))\n",
        "\n",
        "# Calculăm distanța cuantică pentru fiecare pereche de articole\n",
        "for i in range(len(reduced_matrix)):\n",
        "    for j in range(i, len(reduced_matrix)):  # evităm calculul duplicat\n",
        "        state_1_vector = reduced_matrix[i]\n",
        "        state_2_vector = reduced_matrix[j]\n",
        "\n",
        "        # Creăm stările cuantice\n",
        "        state_1 = vector_to_quantum_state(state_1_vector)\n",
        "        state_2 = vector_to_quantum_state(state_2_vector)\n",
        "\n",
        "        # Calculăm distanța cuantică\n",
        "        distance = quantum_distance(state_1, state_2, backend)\n",
        "\n",
        "        # Completăm matricea de similaritate\n",
        "        similarity_matrix[i][j] = distance\n",
        "        similarity_matrix[j][i] = distance  # matrice simetrică\n",
        "\n",
        "# Afișăm matricea de similaritate\n",
        "print(similarity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGhqVtA8nbmo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import pandas as pd\n",
        "\n",
        "# Load the lemmatized CSV\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Quantum feature map function\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Function to compute quantum similarity using fidelity\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "\n",
        "    # Calculating fidelity between each pair of quantum states\n",
        "    fidelities = np.zeros((len(quantum_states), len(quantum_states)))\n",
        "\n",
        "    for i in range(len(quantum_states)):\n",
        "        for j in range(len(quantum_states)):\n",
        "            fidelity = np.abs(np.dot(np.conj(quantum_states[i]), quantum_states[j]))**2\n",
        "            fidelities[i][j] =  fidelity\n",
        "            fidelities[j][i] =  fidelity\n",
        "\n",
        "    return fidelities\n",
        "\n",
        "# Step 1: Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "n_components = 6  # Matches number of qubits\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Step 3: Compute quantum similarity using fidelity\n",
        "fidelity_matrix = quantum_similarity(reduced_matrix)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVYXs2iO1HSg",
        "outputId": "aeb2b112-7ea9-43d4-8746-505ccd15326d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**COD BUN !!!!!!!!!!!!!!!**\n",
        "⏬\n",
        "\n"
      ],
      "metadata": {
        "id": "xIOddIvPmhcH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sCjGNp7srIq4"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import pandas as pd\n",
        "np.random.seed(42)\n",
        "\n",
        "# Load the lemmatized CSV\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Quantum feature map function\n",
        "fixed_weights = np.random.random(size=(1, 8))\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        # weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=fixed_weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Function to compute quantum similarity using fidelity\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "\n",
        "    # Calculating fidelity between each pair of quantum states\n",
        "    fidelities = np.zeros((len(quantum_states), len(quantum_states)))\n",
        "\n",
        "    for i in range(len(quantum_states)):\n",
        "        for j in range(len(quantum_states)):\n",
        "            if i<=j:\n",
        "              # Convert the quantum state vectors to density matrices\n",
        "              state_i = qml.math.dm_from_state_vector(quantum_states[i])\n",
        "              state_j = qml.math.dm_from_state_vector(quantum_states[j])\n",
        "\n",
        "              # Calculate the fidelity between the two states\n",
        "              fidelity = qml.math.fidelity(state_i, state_j)\n",
        "              fidelities[i][j] = fidelity\n",
        "              fidelities[j][i] = fidelity\n",
        "        print(\"I ul curent este \", i)\n",
        "    return fidelities\n",
        "\n",
        "# Step 1: Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "n_components = 8  # Matches number of qubits\n",
        "svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Step 3: Compute quantum similarity using fidelity\n",
        "fidelity_matrix = quantum_similarity(reduced_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpiwSbplnyqq",
        "outputId": "0b20ced2-97ed-4b5a-9da6-e9a7b302c719"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((490, 490), True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "def check_matrix_symmetry(matrix):\n",
        "    shape = matrix.shape\n",
        "    symmetric = np.allclose(matrix, matrix.T)\n",
        "    return shape, symmetric\n",
        "check_matrix_symmetry(fidelity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUVAhdsfn3oe",
        "outputId": "0ff34163-8b68-4bfc-d332-36c63d0a9b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.00000059 0.96688488 0.95786323 ... 0.90089951 0.85572687 0.88607965]\n",
            " [0.96688488 1.00000058 0.98399782 ... 0.90485392 0.85859203 0.90203856]\n",
            " [0.95786323 0.98399782 1.00000063 ... 0.92824918 0.86843871 0.90701477]\n",
            " ...\n",
            " [0.90089951 0.90485392 0.92824918 ... 1.00000057 0.97767739 0.98635565]\n",
            " [0.85572687 0.85859203 0.86843871 ... 0.97767739 1.00000056 0.99206412]\n",
            " [0.88607965 0.90203856 0.90701477 ... 0.98635565 0.99206412 1.00000057]]\n"
          ]
        }
      ],
      "source": [
        "print(fidelity_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS2vfpr_wjhP",
        "outputId": "75efb765-0884-471d-d3f1-e287c8f242df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Top 5 similarități salvate în: /content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_top_fidelity_qml_formula_quantum_social_8_qubiti.csv\n",
            "Nr de articole cu diferite categorii: 0\n",
            "Total predicții corecte: 2450 (100.00%)\n",
            "Total predicții greșite: 0 (0.00%)\n",
            "Articole cu 100% acuratețe: 490 (100.00%)\n",
            "Articole cu cel puțin o diferență: 0 (0.00%)\n",
            "Media acurateților: 100.00%\n",
            "Timp de execuție: 0.46 secunde\n",
            "\n",
            "📄 Log salvat în: /content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_execution_log_8_qubiti_qml.txt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Calea către fișierul de intrare\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "# Citim datele\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Matricea de similaritate trebuie să fie deja definită\n",
        "# Exemplu: similarity_matrix = np.load(\"similarity_matrix.npy\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "top_similarities = {}\n",
        "nr_diferente = 0\n",
        "total_corecte = 0\n",
        "accuracies = []\n",
        "perfect_matches = 0\n",
        "at_least_one_mismatch = 0\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    similarities = fidelity_matrix[i]\n",
        "    top_5_indices = np.argsort(similarities)[-6:-1][::-1]  # Top 5, excluzând self\n",
        "\n",
        "    current_category = df.iloc[i][\"Category\"]  # Categoria articolului curent\n",
        "    nr_corecte = 0  # Număr de predicții corecte pentru acest articol\n",
        "    top_5_info = []\n",
        "\n",
        "    for idx in top_5_indices:\n",
        "        title = df.iloc[idx][\"Title\"]\n",
        "        category = df.iloc[idx][\"Category\"]\n",
        "        similarity_percentage = similarities[idx] * 100  # Convertit la procentaj\n",
        "\n",
        "        top_5_info.append(f\"{df.iloc[idx]['Index']} - {title} - {category} - {similarity_percentage:.2f}%\")\n",
        "\n",
        "        if category == current_category:\n",
        "            nr_corecte += 1\n",
        "        else:\n",
        "            nr_diferente += 1\n",
        "\n",
        "    # Calculăm acuratețea pentru această intrare\n",
        "    accuracy = (nr_corecte / 5) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    if nr_corecte == 5:\n",
        "        perfect_matches += 1\n",
        "    else:\n",
        "        at_least_one_mismatch += 1\n",
        "\n",
        "    total_corecte += nr_corecte\n",
        "    top_similarities[row[\"Index\"]] = top_5_info\n",
        "\n",
        "# Calculul statisticilor generale\n",
        "total_predicted = len(df) * 5\n",
        "correct_percentage = (total_corecte / total_predicted) * 100\n",
        "different_percentage = (nr_diferente / total_predicted) * 100\n",
        "perfect_match_percentage = (perfect_matches / len(df)) * 100\n",
        "at_least_one_mismatch_percentage = (at_least_one_mismatch / len(df)) * 100\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "execution_time = time.time() - start_time\n",
        "\n",
        "# Pregătim datele pentru CSV\n",
        "final_data = []\n",
        "\n",
        "for index, top_articles in top_similarities.items():\n",
        "    current_title = df.loc[df[\"Index\"] == index, \"Title\"].values[0]\n",
        "    current_category = df.loc[df[\"Index\"] == index, \"Category\"].values[0]\n",
        "    # Prima coloană: Index + Title + Category\n",
        "    row_data = [f\"{index} - {current_title} - {current_category}\"]\n",
        "\n",
        "    # Adăugăm top 5 articole similare\n",
        "    row_data.extend(top_articles)\n",
        "    final_data.append(row_data)\n",
        "\n",
        "# Convertim la DataFrame\n",
        "columns = [\"Index + Title + Category\", \"Top1\", \"Top2\", \"Top3\", \"Top4\", \"Top5\"]\n",
        "similarities_df = pd.DataFrame(final_data, columns=columns)\n",
        "\n",
        "# Salvăm în CSV\n",
        "output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_top_fidelity_qml_formula_quantum_social_8_qubiti.csv\"\n",
        "similarities_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Pregătim mesajele de ieșire\n",
        "log_output = f\"\"\"\n",
        "✅ Top 5 similarități salvate în: {output_file}\n",
        "Nr de articole cu diferite categorii: {nr_diferente}\n",
        "Total predicții corecte: {total_corecte} ({correct_percentage:.2f}%)\n",
        "Total predicții greșite: {nr_diferente} ({different_percentage:.2f}%)\n",
        "Articole cu 100% acuratețe: {perfect_matches} ({perfect_match_percentage:.2f}%)\n",
        "Articole cu cel puțin o diferență: {at_least_one_mismatch} ({at_least_one_mismatch_percentage:.2f}%)\n",
        "Media acurateților: {mean_accuracy:.2f}%\n",
        "Timp de execuție: {execution_time:.2f} secunde\n",
        "\"\"\"\n",
        "\n",
        "# Afișăm și salvăm log-ul\n",
        "print(log_output)\n",
        "log_file = \"/content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_execution_log_8_qubiti_qml.txt\"\n",
        "with open(log_file, \"w\") as f:\n",
        "    f.write(log_output)\n",
        "\n",
        "print(f\"📄 Log salvat în: {log_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4RzOMSIssRT"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**varianta cosinus similarity**"
      ],
      "metadata": {
        "id": "Ifu3HxYhnXU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "\n",
        "# Load the lemmatized CSV\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "df = pd.read_csv(input_file)\n",
        "np.random.seed(42)\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "\n",
        "# Function to compute quantum similarity\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "    quantum_real_parts = [np.real(state) for state in quantum_states]\n",
        "    similarities = cosine_similarity(quantum_real_parts)\n",
        "    return similarities\n",
        "\n",
        "# Step 1: Convert text to vectors using TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=1000)\n",
        "tfidf_matrix = vectorizer.fit_transform(df[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "# Step 2: Dimensionality Reduction\n",
        "n_components = 10  # Matches number of qubits\n",
        "svd = TruncatedSVD(n_components=n_components)\n",
        "reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "# Step 3: Compute quantum similarity\n",
        "similarity_matrix = quantum_similarity(reduced_matrix)"
      ],
      "metadata": {
        "id": "-BoD9KCene5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(similarity_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3dV0weRsQXf",
        "outputId": "8fa1fba7-c90a-412e-ae44-fa559df05103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.         0.98302635 0.97593355 ... 0.94305367 0.92239801 0.93895317]\n",
            " [0.98302635 1.         0.99123984 ... 0.9465768  0.92368871 0.94783661]\n",
            " [0.97593355 0.99123984 1.         ... 0.96384399 0.93434549 0.95558592]\n",
            " ...\n",
            " [0.94305367 0.9465768  0.96384399 ... 1.         0.98736214 0.99281218]\n",
            " [0.92239801 0.92368871 0.93434549 ... 0.98736214 1.         0.99553476]\n",
            " [0.93895317 0.94783661 0.95558592 ... 0.99281218 0.99553476 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[1.         0.71197838 0.79392799 ... 0.68333271 0.75762806 0.71194572]\n",
        " [0.71197838 1.         0.71872502 ... 0.70565348 0.78031991 0.76131733]\n",
        " [0.79392799 0.71872502 1.         ... 0.63175165 0.71738714 0.78823688]\n",
        " ...\n",
        " [0.68333271 0.70565348 0.63175165 ... 1.         0.74284153 0.70123683]\n",
        " [0.75762806 0.78031991 0.71738714 ... 0.74284153 1.         0.84758966]\n",
        " [0.71194572 0.76131733 0.78823688 ... 0.70123683 0.84758966 1.        ]]\n",
        "\n"
      ],
      "metadata": {
        "id": "lQOx4YCnt43X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[[1.         0.96935705 0.96011513 ... 0.933226   0.90596794 0.92726629]\n",
        " [0.96935705 1.         0.9858136  ... 0.94720817 0.92206141 0.94789515]\n",
        " [0.96011513 0.9858136  1.         ... 0.95318384 0.91932352 0.9504873 ]\n",
        " ...\n",
        " [0.933226   0.94720817 0.95318384 ... 1.         0.98577229 0.99003615]\n",
        " [0.90596794 0.92206141 0.91932352 ... 0.98577229 1.         0.9918305 ]\n",
        " [0.92726629 0.94789515 0.9504873  ... 0.99003615 0.9918305  1.        ]]"
      ],
      "metadata": {
        "id": "uwrvQgSTwASr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Calea către fișierul de intrare\n",
        "input_file = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "\n",
        "# Citim datele\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Matricea de similaritate trebuie să fie deja definită\n",
        "# Exemplu: similarity_matrix = np.load(\"similarity_matrix.npy\")\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "top_similarities = {}\n",
        "nr_diferente = 0\n",
        "total_corecte = 0\n",
        "accuracies = []\n",
        "perfect_matches = 0\n",
        "at_least_one_mismatch = 0\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    similarities = similarity_matrix[i]\n",
        "    top_5_indices = np.argsort(similarities)[-6:-1][::-1]  # Top 5, excluzând self\n",
        "\n",
        "    current_category = df.iloc[i][\"Category\"]  # Categoria articolului curent\n",
        "    nr_corecte = 0  # Număr de predicții corecte pentru acest articol\n",
        "    top_5_info = []\n",
        "\n",
        "    for idx in top_5_indices:\n",
        "        title = df.iloc[idx][\"Title\"]\n",
        "        category = df.iloc[idx][\"Category\"]\n",
        "        similarity_percentage = similarities[idx] * 100  # Convertit la procentaj\n",
        "\n",
        "        top_5_info.append(f\"{df.iloc[idx]['Index']} - {title} - {category} - {similarity_percentage:.2f}%\")\n",
        "\n",
        "        if category == current_category:\n",
        "            nr_corecte += 1\n",
        "        else:\n",
        "            nr_diferente += 1\n",
        "\n",
        "    # Calculăm acuratețea pentru această intrare\n",
        "    accuracy = (nr_corecte / 5) * 100\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "    if nr_corecte == 5:\n",
        "        perfect_matches += 1\n",
        "    else:\n",
        "        at_least_one_mismatch += 1\n",
        "\n",
        "    total_corecte += nr_corecte\n",
        "    top_similarities[row[\"Index\"]] = top_5_info\n",
        "\n",
        "# Calculul statisticilor generale\n",
        "total_predicted = len(df) * 5\n",
        "correct_percentage = (total_corecte / total_predicted) * 100\n",
        "different_percentage = (nr_diferente / total_predicted) * 100\n",
        "perfect_match_percentage = (perfect_matches / len(df)) * 100\n",
        "at_least_one_mismatch_percentage = (at_least_one_mismatch / len(df)) * 100\n",
        "mean_accuracy = np.mean(accuracies)\n",
        "execution_time = time.time() - start_time\n",
        "\n",
        "# Pregătim datele pentru CSV\n",
        "final_data = []\n",
        "\n",
        "for index, top_articles in top_similarities.items():\n",
        "    current_title = df.loc[df[\"Index\"] == index, \"Title\"].values[0]\n",
        "    current_category = df.loc[df[\"Index\"] == index, \"Category\"].values[0]\n",
        "    # Prima coloană: Index + Title + Category\n",
        "    row_data = [f\"{index} - {current_title} - {current_category}\"]\n",
        "\n",
        "    # Adăugăm top 5 articole similare\n",
        "    row_data.extend(top_articles)\n",
        "    final_data.append(row_data)\n",
        "\n",
        "# Convertim la DataFrame\n",
        "columns = [\"Index + Title + Category\", \"Top1\", \"Top2\", \"Top3\", \"Top4\", \"Top5\"]\n",
        "similarities_df = pd.DataFrame(final_data, columns=columns)\n",
        "\n",
        "# Salvăm în CSV\n",
        "output_file = \"/content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_top_cos_similarties_15_qubiti.csv\"\n",
        "# similarities_df.to_csv(output_file, index=False)\n",
        "\n",
        "# Pregătim mesajele de ieșire\n",
        "log_output = f\"\"\"\n",
        "✅ Top 5 similarități salvate în: {output_file}\n",
        "Nr de articole cu diferite categorii: {nr_diferente}\n",
        "Total predicții corecte: {total_corecte} ({correct_percentage:.2f}%)\n",
        "Total predicții greșite: {nr_diferente} ({different_percentage:.2f}%)\n",
        "Articole cu 100% acuratețe: {perfect_matches} ({perfect_match_percentage:.2f}%)\n",
        "Articole cu cel puțin o diferență: {at_least_one_mismatch} ({at_least_one_mismatch_percentage:.2f}%)\n",
        "Media acurateților: {mean_accuracy:.2f}%\n",
        "Timp de execuție: {execution_time:.2f} secunde\n",
        "\"\"\"\n",
        "\n",
        "# Afișăm și salvăm log-ul\n",
        "print(log_output)\n",
        "log_file = \"/content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_execution_log_cosi_similarities-10-qubiti.txt\"\n",
        "with open(log_file, \"w\") as f:\n",
        "    f.write(log_output)\n",
        "\n",
        "print(f\"📄 Log salvat în: {log_file}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeYDkHEqoBbU",
        "outputId": "32d6fb6d-434f-48b6-91c4-c9fd896c5541"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Top 5 similarități salvate în: /content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_top_cos_similarties_15_qubiti.csv\n",
            "Nr de articole cu diferite categorii: 0\n",
            "Total predicții corecte: 2450 (100.00%)\n",
            "Total predicții greșite: 0 (0.00%)\n",
            "Articole cu 100% acuratețe: 490 (100.00%)\n",
            "Articole cu cel puțin o diferență: 0 (0.00%)\n",
            "Media acurateților: 100.00%\n",
            "Timp de execuție: 0.92 secunde\n",
            "\n",
            "📄 Log salvat în: /content/drive/MyDrive/QuantumElearningDataSet/3_aprilie_execution_log_cosi_similarities-10-qubiti.txt\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08979dbc6d9b4f16a76d6565a059be73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1143e2d95c5a45208fcaf2c479da3995": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c42c78409e644f69b9b82a5aa0df9cb5",
            "max": 1.532592717,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2d314f23d63244d6b59acde7f9882597",
            "value": 1.5325927169612208
          }
        },
        "13a473b654594a48aa8bb39eee15e506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b358003faa4f53bb0103116237c949": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc68ca2e7874e4dbe37ddcb581b0dce",
            "placeholder": "​",
            "style": "IPY_MODEL_f63c897a352643c5a68484f5ac0571ee",
            "value": "1.533/1.533GB [00:11&lt;00:00]"
          }
        },
        "2d314f23d63244d6b59acde7f9882597": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3145e7029f52479ea38f93d49496e1ee": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36447226f91941c1a40bf1cfe3fe7663": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec5052134301476490dd9d2ba8de10de",
              "IPY_MODEL_c3b7b85bc182462f8fce0df209d590f2",
              "IPY_MODEL_25b358003faa4f53bb0103116237c949"
            ],
            "layout": "IPY_MODEL_3145e7029f52479ea38f93d49496e1ee"
          }
        },
        "452b0143cd3e4790b7592593063e4a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5ca20fdcdc64eee89655539ecf76925",
              "IPY_MODEL_1143e2d95c5a45208fcaf2c479da3995",
              "IPY_MODEL_d640f2706cdd4b43acbbeb40f4f774c7"
            ],
            "layout": "IPY_MODEL_9b171099b7a34c98928e10cbe9792593"
          }
        },
        "4ced78a61b7e4a01ba1bb198fd18f0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64edcbfd544d45daa11bbb687552e05f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80dcd5582380403ab63ea99d23f0317e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "899efb3cde3a496fa0b0b2cc7a37d8dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1dd51c33414094bd32704c42cc6f14": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b171099b7a34c98928e10cbe9792593": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa44c5c6da90435996395596f136d2d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc68ca2e7874e4dbe37ddcb581b0dce": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3b7b85bc182462f8fce0df209d590f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_899efb3cde3a496fa0b0b2cc7a37d8dc",
            "max": 1.532592717,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa44c5c6da90435996395596f136d2d5",
            "value": 1.5325927169612208
          }
        },
        "c42c78409e644f69b9b82a5aa0df9cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d640f2706cdd4b43acbbeb40f4f774c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1dd51c33414094bd32704c42cc6f14",
            "placeholder": "​",
            "style": "IPY_MODEL_4ced78a61b7e4a01ba1bb198fd18f0c6",
            "value": "1.533/1.533GB [01:15&lt;00:00]"
          }
        },
        "ec5052134301476490dd9d2ba8de10de": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08979dbc6d9b4f16a76d6565a059be73",
            "placeholder": "​",
            "style": "IPY_MODEL_13a473b654594a48aa8bb39eee15e506",
            "value": "Evaluating checksum: 100.0%"
          }
        },
        "f5ca20fdcdc64eee89655539ecf76925": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64edcbfd544d45daa11bbb687552e05f",
            "placeholder": "​",
            "style": "IPY_MODEL_80dcd5582380403ab63ea99d23f0317e",
            "value": "Downloading model: 100.0%"
          }
        },
        "f63c897a352643c5a68484f5ac0571ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}