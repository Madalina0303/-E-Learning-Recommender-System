{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install pennylane torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVGMOGO4wxMq",
        "outputId": "64c92d66-6201-447e-ddec-2a3d61f083b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.40.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy<2.1 in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\n",
            "Collecting rustworkx>=0.14.0 (from pennylane)\n",
            "  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\n",
            "Collecting tomlkit (from pennylane)\n",
            "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting appdirs (from pennylane)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting autoray>=0.6.11 (from pennylane)\n",
            "  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\n",
            "Collecting pennylane-lightning>=0.40 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (27 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (24.2)\n",
            "Collecting diastatic-malt (from pennylane)\n",
            "  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Collecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.40->pennylane)\n",
            "  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\n",
            "Requirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\n",
            "Requirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\n",
            "Downloading PennyLane-0.40.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m804.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading PennyLane_Lightning-0.40.0-cp311-cp311-manylinux_2_28_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
            "Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, rustworkx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, autoray, nvidia-cusparse-cu12, nvidia-cudnn-cu12, diastatic-malt, nvidia-cusolver-cu12, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pennylane-0.40.0 pennylane-lightning-0.40.0 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oe9tKh8VspXk",
        "outputId": "671f8d20-35a4-4693-d4ff-6c3a005d8215"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Run 1/5\n",
            "========================================\n",
            "Run 1 Results:\n",
            "✅ Correct: 2359 (96.29%)\n",
            "❌ Wrong: 91 (3.71%)\n",
            "🎯 Perfect: 457 (93.27%)\n",
            "⚠️ Mismatch: 33 (6.73%)\n",
            "📊 Accuracy: 96.29%\n",
            "⏱️ Time: 21.02s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 2/5\n",
            "========================================\n",
            "Run 2 Results:\n",
            "✅ Correct: 2365 (96.53%)\n",
            "❌ Wrong: 85 (3.47%)\n",
            "🎯 Perfect: 459 (93.67%)\n",
            "⚠️ Mismatch: 31 (6.33%)\n",
            "📊 Accuracy: 96.53%\n",
            "⏱️ Time: 22.45s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 3/5\n",
            "========================================\n",
            "Run 3 Results:\n",
            "✅ Correct: 2366 (96.57%)\n",
            "❌ Wrong: 84 (3.43%)\n",
            "🎯 Perfect: 461 (94.08%)\n",
            "⚠️ Mismatch: 29 (5.92%)\n",
            "📊 Accuracy: 96.57%\n",
            "⏱️ Time: 19.15s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 4/5\n",
            "========================================\n",
            "Run 4 Results:\n",
            "✅ Correct: 2380 (97.14%)\n",
            "❌ Wrong: 70 (2.86%)\n",
            "🎯 Perfect: 455 (92.86%)\n",
            "⚠️ Mismatch: 35 (7.14%)\n",
            "📊 Accuracy: 97.14%\n",
            "⏱️ Time: 22.63s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 5/5\n",
            "========================================\n",
            "Run 5 Results:\n",
            "✅ Correct: 2364 (96.49%)\n",
            "❌ Wrong: 86 (3.51%)\n",
            "🎯 Perfect: 458 (93.47%)\n",
            "⚠️ Mismatch: 32 (6.53%)\n",
            "📊 Accuracy: 96.49%\n",
            "⏱️ Time: 19.31s\n",
            "\n",
            "\n",
            "========================================\n",
            "FINAL SUMMARY AFTER 5 RUNS\n",
            "Average correct: 96.60%\n",
            "Average wrong: 3.40%\n",
            "Average perfect: 93.47%\n",
            "Average mismatch: 6.53%\n",
            "Overall accuracy: 96.60%\n",
            "Average time: 20.91s\n",
            "\n",
            "📄 Full log saved to: /content/drive/MyDrive/Quantum-LogFiles/15_cos_similarity_logs.txt\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Configurații\n",
        "NUM_RUNS = 5  # Numărul de rulări\n",
        "PREPROCESSED_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "MAIN_DATA_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "OUTPUT_FILE = \"/content/drive/MyDrive/Quantum-LogFiles/15_cos_similarity_results.csv\"\n",
        "LOG_FILE = \"/content/drive/MyDrive/Quantum-LogFiles/15_cos_similarity_logs.txt\"\n",
        "N_QUBITS = 15  # Numărul de qubiți pentru circuitul cuantic\n",
        "\n",
        "# Funcție pentru maparea caracteristicilor cuantice\n",
        "def quantum_feature_map(x, run_id):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Funcție pentru calculul similarității cuantice\n",
        "def quantum_similarity(vectors, run_id):\n",
        "    quantum_states = [quantum_feature_map(vec, run_id) for vec in vectors]\n",
        "    quantum_real_parts = [np.real(state) for state in quantum_states]\n",
        "    similarities = cosine_similarity(quantum_real_parts)\n",
        "    return similarities\n",
        "\n",
        "# Funcție pentru preprocesarea datelor\n",
        "def preprocess_data():\n",
        "    # Încărcare date preprocesate\n",
        "    df_processed = pd.read_csv(PREPROCESSED_FILE)\n",
        "\n",
        "    # Convertire text în vectori TF-IDF\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df_processed[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "    # Reducere dimensionalitate\n",
        "    svd = TruncatedSVD(n_components=N_QUBITS)\n",
        "    reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "    return reduced_matrix\n",
        "\n",
        "# Funcție pentru rularea unei singure iterații\n",
        "def run_single_iteration(run_id, df, reduced_matrix):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generare matrice de similaritate cuantică\n",
        "    similarity_matrix = quantum_similarity(reduced_matrix, run_id)\n",
        "\n",
        "    metrics = {\n",
        "        'run_id': run_id,\n",
        "        'nr_diferente': 0,\n",
        "        'total_corecte': 0,\n",
        "        'perfect_matches': 0,\n",
        "        'at_least_one_mismatch': 0,\n",
        "        'accuracies': []\n",
        "    }\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        similarities = similarity_matrix[i]\n",
        "        top_5_indices = np.argsort(similarities)[-6:-1][::-1]\n",
        "        current_category = df.iloc[i][\"Category\"]\n",
        "        nr_corecte = sum(df.iloc[idx][\"Category\"] == current_category for idx in top_5_indices)\n",
        "\n",
        "        metrics['accuracies'].append((nr_corecte / 5) * 100)\n",
        "        metrics['total_corecte'] += nr_corecte\n",
        "        metrics['nr_diferente'] += (5 - nr_corecte)\n",
        "\n",
        "        if nr_corecte == 5:\n",
        "            metrics['perfect_matches'] += 1\n",
        "        else:\n",
        "            metrics['at_least_one_mismatch'] += 1\n",
        "\n",
        "    # Calcul metrici finale\n",
        "    total_predicted = len(df) * 5\n",
        "    metrics.update({\n",
        "        'correct_percentage': (metrics['total_corecte'] / total_predicted) * 100,\n",
        "        'different_percentage': (metrics['nr_diferente'] / total_predicted) * 100,\n",
        "        'perfect_match_percentage': (metrics['perfect_matches'] / len(df)) * 100,\n",
        "        'mismatch_percentage': (metrics['at_least_one_mismatch'] / len(df)) * 100,\n",
        "        'mean_accuracy': np.mean(metrics['accuracies']),\n",
        "        'execution_time': time.time() - start_time\n",
        "    })\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Pregătire fișier de log\n",
        "with open(LOG_FILE, \"w\") as f:\n",
        "    f.write(f\"Quantum Similarity Experiment - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Configuration: {NUM_RUNS} runs, {N_QUBITS} qubits\\n\\n\")\n",
        "\n",
        "# Încărcare date principale\n",
        "df_main = pd.read_csv(MAIN_DATA_FILE)\n",
        "reduced_matrix = preprocess_data()\n",
        "all_metrics = []\n",
        "\n",
        "# Rulări multiple\n",
        "for run in range(1, NUM_RUNS+1):\n",
        "    print(f\"\\n{'='*40}\\nRun {run}/{NUM_RUNS}\\n{'='*40}\")\n",
        "\n",
        "    metrics = run_single_iteration(run, df_main, reduced_matrix)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Scriere log\n",
        "    log_entry = f\"\"\"Run {run} Results:\n",
        "✅ Correct: {metrics['total_corecte']} ({metrics['correct_percentage']:.2f}%)\n",
        "❌ Wrong: {metrics['nr_diferente']} ({metrics['different_percentage']:.2f}%)\n",
        "🎯 Perfect: {metrics['perfect_matches']} ({metrics['perfect_match_percentage']:.2f}%)\n",
        "⚠️ Mismatch: {metrics['at_least_one_mismatch']} ({metrics['mismatch_percentage']:.2f}%)\n",
        "📊 Accuracy: {metrics['mean_accuracy']:.2f}%\n",
        "⏱️ Time: {metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(log_entry)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(log_entry)\n",
        "\n",
        "# Calcul medii\n",
        "if NUM_RUNS > 1:\n",
        "    avg_metrics = {\n",
        "        'correct_percentage': np.mean([m['correct_percentage'] for m in all_metrics]),\n",
        "        'different_percentage': np.mean([m['different_percentage'] for m in all_metrics]),\n",
        "        'perfect_match_percentage': np.mean([m['perfect_match_percentage'] for m in all_metrics]),\n",
        "        'mismatch_percentage': np.mean([m['mismatch_percentage'] for m in all_metrics]),\n",
        "        'mean_accuracy': np.mean([m['mean_accuracy'] for m in all_metrics]),\n",
        "        'execution_time': np.mean([m['execution_time'] for m in all_metrics])\n",
        "    }\n",
        "\n",
        "    summary_log = f\"\"\"\\n{'='*40}\n",
        "FINAL SUMMARY AFTER {NUM_RUNS} RUNS\n",
        "Average correct: {avg_metrics['correct_percentage']:.2f}%\n",
        "Average wrong: {avg_metrics['different_percentage']:.2f}%\n",
        "Average perfect: {avg_metrics['perfect_match_percentage']:.2f}%\n",
        "Average mismatch: {avg_metrics['mismatch_percentage']:.2f}%\n",
        "Overall accuracy: {avg_metrics['mean_accuracy']:.2f}%\n",
        "Average time: {avg_metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(summary_log)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(summary_log)\n",
        "\n",
        "# Salvare rezultate detaliate\n",
        "results_df = pd.DataFrame(all_metrics)\n",
        "# results_df.to_csv(OUTPUT_FILE, index=False)\n",
        "# print(f\"\\n📊 Results saved to: {OUTPUT_FILE}\")\n",
        "print(f\"📄 Full log saved to: {LOG_FILE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METODA 2-QUANTUM FIDELITY"
      ],
      "metadata": {
        "id": "8ypNyjbU2-rc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Configurații\n",
        "NUM_RUNS = 5  # Numărul de rulări\n",
        "PREPROCESSED_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "MAIN_DATA_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "LOG_FILE = \"/content/drive/MyDrive/Quantum-LogFiles/8_quanutum_fidelity_logs.txt_v2\"\n",
        "N_QUBITS = 8  # Numărul de qubiți pentru circuitul cuantic\n",
        "\n",
        "# Funcție pentru maparea caracteristicilor cuantice\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Funcție pentru calculul similarității cuantice\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = np.array([quantum_feature_map(vec) for vec in vectors])\n",
        "    density_matrices = qml.math.dm_from_state_vector(quantum_states)  # Vectorizat\n",
        "\n",
        "    # Calcul fidelitate pairwise folosind broadcasting\n",
        "    n = len(quantum_states)\n",
        "    fidelities = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(i, n):  # Triunghi superior\n",
        "            fidelities[i][j] = qml.math.fidelity(density_matrices[i], density_matrices[j])\n",
        "            fidelities[j][i] = fidelities[i][j]  # Simetrie\n",
        "    return fidelities\n",
        "\n",
        "# def quantum_similarity(vectors):\n",
        "#     quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "#     fidelities = np.zeros((len(quantum_states), len(quantum_states)))\n",
        "\n",
        "#     for i in range(len(quantum_states)):\n",
        "#         for j in range(len(quantum_states)):\n",
        "#             if i<=j:\n",
        "#               # Convert the quantum state vectors to density matrices\n",
        "#               state_i = qml.math.dm_from_state_vector(quantum_states[i])\n",
        "#               state_j = qml.math.dm_from_state_vector(quantum_states[j])\n",
        "\n",
        "#               # Calculate the fidelity between the two states\n",
        "#               fidelity = qml.math.fidelity(state_i, state_j)\n",
        "#               fidelities[i][j] = fidelity\n",
        "#               fidelities[j][i] = fidelity\n",
        "#     return fidelities\n",
        "\n",
        "# Funcție pentru preprocesarea datelor\n",
        "def preprocess_data():\n",
        "    # Încărcare date preprocesate\n",
        "    df_processed = pd.read_csv(PREPROCESSED_FILE)\n",
        "\n",
        "    # Convertire text în vectori TF-IDF\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df_processed[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "    # Reducere dimensionalitate\n",
        "    svd = TruncatedSVD(n_components=N_QUBITS)\n",
        "    reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "    return reduced_matrix\n",
        "\n",
        "# Funcție pentru rularea unei singure iterații\n",
        "def run_single_iteration(run_id, df, reduced_matrix):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generare matrice de similaritate cuantică\n",
        "    similarity_matrix = quantum_similarity(reduced_matrix)\n",
        "\n",
        "    metrics = {\n",
        "        'run_id': run_id,\n",
        "        'nr_diferente': 0,\n",
        "        'total_corecte': 0,\n",
        "        'perfect_matches': 0,\n",
        "        'at_least_one_mismatch': 0,\n",
        "        'accuracies': []\n",
        "    }\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        similarities = similarity_matrix[i]\n",
        "        top_5_indices = np.argsort(similarities)[-6:-1][::-1]\n",
        "        current_category = df.iloc[i][\"Category\"]\n",
        "        nr_corecte = sum(df.iloc[idx][\"Category\"] == current_category for idx in top_5_indices)\n",
        "\n",
        "        metrics['accuracies'].append((nr_corecte / 5) * 100)\n",
        "        metrics['total_corecte'] += nr_corecte\n",
        "        metrics['nr_diferente'] += (5 - nr_corecte)\n",
        "\n",
        "        if nr_corecte == 5:\n",
        "            metrics['perfect_matches'] += 1\n",
        "        else:\n",
        "            metrics['at_least_one_mismatch'] += 1\n",
        "\n",
        "    # Calcul metrici finale\n",
        "    total_predicted = len(df) * 5\n",
        "    metrics.update({\n",
        "        'correct_percentage': (metrics['total_corecte'] / total_predicted) * 100,\n",
        "        'different_percentage': (metrics['nr_diferente'] / total_predicted) * 100,\n",
        "        'perfect_match_percentage': (metrics['perfect_matches'] / len(df)) * 100,\n",
        "        'mismatch_percentage': (metrics['at_least_one_mismatch'] / len(df)) * 100,\n",
        "        'mean_accuracy': np.mean(metrics['accuracies']),\n",
        "        'execution_time': time.time() - start_time\n",
        "    })\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Pregătire fișier de log\n",
        "with open(LOG_FILE, \"w\") as f:\n",
        "    f.write(f\"Quantum Similarity Experiment - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Configuration: {NUM_RUNS} runs, {N_QUBITS} qubits\\n\\n\")\n",
        "\n",
        "# Încărcare date principale\n",
        "df_main = pd.read_csv(MAIN_DATA_FILE)\n",
        "reduced_matrix = preprocess_data()\n",
        "all_metrics = []\n",
        "\n",
        "# Rulări multiple\n",
        "for run in range(1, NUM_RUNS+1):\n",
        "    print(f\"\\n{'='*40}\\nRun {run}/{NUM_RUNS}\\n{'='*40}\")\n",
        "\n",
        "    metrics = run_single_iteration(run, df_main, reduced_matrix)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Scriere log\n",
        "    log_entry = f\"\"\"Run {run} Results:\n",
        "✅ Correct: {metrics['total_corecte']} ({metrics['correct_percentage']:.2f}%)\n",
        "❌ Wrong: {metrics['nr_diferente']} ({metrics['different_percentage']:.2f}%)\n",
        "🎯 Perfect: {metrics['perfect_matches']} ({metrics['perfect_match_percentage']:.2f}%)\n",
        "⚠️ Mismatch: {metrics['at_least_one_mismatch']} ({metrics['mismatch_percentage']:.2f}%)\n",
        "📊 Accuracy: {metrics['mean_accuracy']:.2f}%\n",
        "⏱️ Time: {metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(log_entry)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(log_entry)\n",
        "\n",
        "# Calcul medii\n",
        "if NUM_RUNS > 1:\n",
        "    avg_metrics = {\n",
        "        'correct_percentage': np.mean([m['correct_percentage'] for m in all_metrics]),\n",
        "        'different_percentage': np.mean([m['different_percentage'] for m in all_metrics]),\n",
        "        'perfect_match_percentage': np.mean([m['perfect_match_percentage'] for m in all_metrics]),\n",
        "        'mismatch_percentage': np.mean([m['mismatch_percentage'] for m in all_metrics]),\n",
        "        'mean_accuracy': np.mean([m['mean_accuracy'] for m in all_metrics]),\n",
        "        'execution_time': np.mean([m['execution_time'] for m in all_metrics])\n",
        "    }\n",
        "\n",
        "    summary_log = f\"\"\"\\n{'='*40}\n",
        "FINAL SUMMARY AFTER {NUM_RUNS} RUNS\n",
        "Average correct: {avg_metrics['correct_percentage']:.2f}%\n",
        "Average wrong: {avg_metrics['different_percentage']:.2f}%\n",
        "Average perfect: {avg_metrics['perfect_match_percentage']:.2f}%\n",
        "Average mismatch: {avg_metrics['mismatch_percentage']:.2f}%\n",
        "Overall accuracy: {avg_metrics['mean_accuracy']:.2f}%\n",
        "Average time: {avg_metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(summary_log)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(summary_log)\n",
        "\n",
        "# Salvare rezultate detaliate\n",
        "results_df = pd.DataFrame(all_metrics)\n",
        "# results_df.to_csv(OUTPUT_FILE, index=False)\n",
        "# print(f\"\\n📊 Results saved to: {OUTPUT_FILE}\")\n",
        "print(f\"📄 Full log saved to: {LOG_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BATR-ikB29uD",
        "outputId": "c87eb314-d058-4e05-b716-6b219d773ccc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Run 1/5\n",
            "========================================\n",
            "Run 1 Results:\n",
            "✅ Correct: 2395 (97.76%)\n",
            "❌ Wrong: 55 (2.24%)\n",
            "🎯 Perfect: 468 (95.51%)\n",
            "⚠️ Mismatch: 22 (4.49%)\n",
            "📊 Accuracy: 97.76%\n",
            "⏱️ Time: 12540.67s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 2/5\n",
            "========================================\n",
            "Run 2 Results:\n",
            "✅ Correct: 2406 (98.20%)\n",
            "❌ Wrong: 44 (1.80%)\n",
            "🎯 Perfect: 471 (96.12%)\n",
            "⚠️ Mismatch: 19 (3.88%)\n",
            "📊 Accuracy: 98.20%\n",
            "⏱️ Time: 12261.30s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 3/5\n",
            "========================================\n",
            "Run 3 Results:\n",
            "✅ Correct: 2410 (98.37%)\n",
            "❌ Wrong: 40 (1.63%)\n",
            "🎯 Perfect: 475 (96.94%)\n",
            "⚠️ Mismatch: 15 (3.06%)\n",
            "📊 Accuracy: 98.37%\n",
            "⏱️ Time: 12311.74s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 4/5\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "METODA 3- QML ponderi fixe"
      ],
      "metadata": {
        "id": "TYovFj3xAHR2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from datetime import datetime\n",
        "import pennylane as qml\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "# Configurații\n",
        "NUM_RUNS = 5  # Numărul de rulări\n",
        "PREPROCESSED_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/processed_summaries_q_s.csv\"\n",
        "MAIN_DATA_FILE = \"/content/drive/MyDrive/QuantumElearningDataSet/arxiv_quantum_computing_pdf.csv\"\n",
        "LOG_FILE = \"/content/drive/MyDrive/Quantum-LogFiles/6_quanutum_fidelity_ponderi_fixe_logs.txt\"\n",
        "N_QUBITS = 6  # Numărul de qubiți pentru circuitul cuantic\n",
        "\n",
        "# Funcție pentru maparea caracteristicilor cuantice\n",
        "weights = np.random.random(size=(1, 6))\n",
        "def quantum_feature_map(x):\n",
        "    n_qubits = len(x)\n",
        "    dev = qml.device(\"default.qubit\", wires=n_qubits)\n",
        "    @qml.qnode(dev)\n",
        "    def circuit():\n",
        "        for i, feature in enumerate(x):\n",
        "            qml.RY(feature, wires=i)\n",
        "        # weights = np.random.random(size=(1, n_qubits))\n",
        "        qml.templates.BasicEntanglerLayers(weights=weights, wires=range(n_qubits))\n",
        "        return qml.state()\n",
        "    return circuit()\n",
        "\n",
        "# Funcție pentru calculul similarității cuantice\n",
        "def quantum_similarity(vectors):\n",
        "    quantum_states = np.array([quantum_feature_map(vec) for vec in vectors])\n",
        "    density_matrices = qml.math.dm_from_state_vector(quantum_states)  # Vectorizat\n",
        "\n",
        "    # Calcul fidelitate pairwise folosind broadcasting\n",
        "    n = len(quantum_states)\n",
        "    fidelities = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(i, n):  # Triunghi superior\n",
        "            fidelities[i][j] = qml.math.fidelity(density_matrices[i], density_matrices[j])\n",
        "            fidelities[j][i] = fidelities[i][j]  # Simetrie\n",
        "    return fidelities\n",
        "\n",
        "# def quantum_similarity(vectors):\n",
        "#     quantum_states = [quantum_feature_map(vec) for vec in vectors]\n",
        "#     fidelities = np.zeros((len(quantum_states), len(quantum_states)))\n",
        "\n",
        "#     for i in range(len(quantum_states)):\n",
        "#         for j in range(len(quantum_states)):\n",
        "#             if i<=j:\n",
        "#               # Convert the quantum state vectors to density matrices\n",
        "#               state_i = qml.math.dm_from_state_vector(quantum_states[i])\n",
        "#               state_j = qml.math.dm_from_state_vector(quantum_states[j])\n",
        "\n",
        "#               # Calculate the fidelity between the two states\n",
        "#               fidelity = qml.math.fidelity(state_i, state_j)\n",
        "#               fidelities[i][j] = fidelity\n",
        "#               fidelities[j][i] = fidelity\n",
        "#     return fidelities\n",
        "\n",
        "# Funcție pentru preprocesarea datelor\n",
        "def preprocess_data():\n",
        "    # Încărcare date preprocesate\n",
        "    df_processed = pd.read_csv(PREPROCESSED_FILE)\n",
        "\n",
        "    # Convertire text în vectori TF-IDF\n",
        "    vectorizer = TfidfVectorizer(max_features=1000)\n",
        "    tfidf_matrix = vectorizer.fit_transform(df_processed[\"Processed_Summary\"]).toarray()\n",
        "\n",
        "    # Reducere dimensionalitate\n",
        "    svd = TruncatedSVD(n_components=N_QUBITS)\n",
        "    reduced_matrix = svd.fit_transform(tfidf_matrix)\n",
        "\n",
        "    return reduced_matrix\n",
        "\n",
        "# Funcție pentru rularea unei singure iterații\n",
        "def run_single_iteration(run_id, df, reduced_matrix):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generare matrice de similaritate cuantică\n",
        "    similarity_matrix = quantum_similarity(reduced_matrix)\n",
        "\n",
        "    metrics = {\n",
        "        'run_id': run_id,\n",
        "        'nr_diferente': 0,\n",
        "        'total_corecte': 0,\n",
        "        'perfect_matches': 0,\n",
        "        'at_least_one_mismatch': 0,\n",
        "        'accuracies': []\n",
        "    }\n",
        "\n",
        "    for i, row in df.iterrows():\n",
        "        similarities = similarity_matrix[i]\n",
        "        top_5_indices = np.argsort(similarities)[-6:-1][::-1]\n",
        "        current_category = df.iloc[i][\"Category\"]\n",
        "        nr_corecte = sum(df.iloc[idx][\"Category\"] == current_category for idx in top_5_indices)\n",
        "\n",
        "        metrics['accuracies'].append((nr_corecte / 5) * 100)\n",
        "        metrics['total_corecte'] += nr_corecte\n",
        "        metrics['nr_diferente'] += (5 - nr_corecte)\n",
        "\n",
        "        if nr_corecte == 5:\n",
        "            metrics['perfect_matches'] += 1\n",
        "        else:\n",
        "            metrics['at_least_one_mismatch'] += 1\n",
        "\n",
        "    # Calcul metrici finale\n",
        "    total_predicted = len(df) * 5\n",
        "    metrics.update({\n",
        "        'correct_percentage': (metrics['total_corecte'] / total_predicted) * 100,\n",
        "        'different_percentage': (metrics['nr_diferente'] / total_predicted) * 100,\n",
        "        'perfect_match_percentage': (metrics['perfect_matches'] / len(df)) * 100,\n",
        "        'mismatch_percentage': (metrics['at_least_one_mismatch'] / len(df)) * 100,\n",
        "        'mean_accuracy': np.mean(metrics['accuracies']),\n",
        "        'execution_time': time.time() - start_time\n",
        "    })\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Pregătire fișier de log\n",
        "with open(LOG_FILE, \"w\") as f:\n",
        "    f.write(f\"Quantum Similarity Experiment - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Configuration: {NUM_RUNS} runs, {N_QUBITS} qubits\\n\\n\")\n",
        "\n",
        "# Încărcare date principale\n",
        "df_main = pd.read_csv(MAIN_DATA_FILE)\n",
        "reduced_matrix = preprocess_data()\n",
        "all_metrics = []\n",
        "\n",
        "# Rulări multiple\n",
        "for run in range(1, NUM_RUNS+1):\n",
        "    print(f\"\\n{'='*40}\\nRun {run}/{NUM_RUNS}\\n{'='*40}\")\n",
        "\n",
        "    metrics = run_single_iteration(run, df_main, reduced_matrix)\n",
        "    all_metrics.append(metrics)\n",
        "\n",
        "    # Scriere log\n",
        "    log_entry = f\"\"\"Run {run} Results:\n",
        "✅ Correct: {metrics['total_corecte']} ({metrics['correct_percentage']:.2f}%)\n",
        "❌ Wrong: {metrics['nr_diferente']} ({metrics['different_percentage']:.2f}%)\n",
        "🎯 Perfect: {metrics['perfect_matches']} ({metrics['perfect_match_percentage']:.2f}%)\n",
        "⚠️ Mismatch: {metrics['at_least_one_mismatch']} ({metrics['mismatch_percentage']:.2f}%)\n",
        "📊 Accuracy: {metrics['mean_accuracy']:.2f}%\n",
        "⏱️ Time: {metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(log_entry)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(log_entry)\n",
        "\n",
        "# Calcul medii\n",
        "if NUM_RUNS > 1:\n",
        "    avg_metrics = {\n",
        "        'correct_percentage': np.mean([m['correct_percentage'] for m in all_metrics]),\n",
        "        'different_percentage': np.mean([m['different_percentage'] for m in all_metrics]),\n",
        "        'perfect_match_percentage': np.mean([m['perfect_match_percentage'] for m in all_metrics]),\n",
        "        'mismatch_percentage': np.mean([m['mismatch_percentage'] for m in all_metrics]),\n",
        "        'mean_accuracy': np.mean([m['mean_accuracy'] for m in all_metrics]),\n",
        "        'execution_time': np.mean([m['execution_time'] for m in all_metrics])\n",
        "    }\n",
        "\n",
        "    summary_log = f\"\"\"\\n{'='*40}\n",
        "FINAL SUMMARY AFTER {NUM_RUNS} RUNS\n",
        "Average correct: {avg_metrics['correct_percentage']:.2f}%\n",
        "Average wrong: {avg_metrics['different_percentage']:.2f}%\n",
        "Average perfect: {avg_metrics['perfect_match_percentage']:.2f}%\n",
        "Average mismatch: {avg_metrics['mismatch_percentage']:.2f}%\n",
        "Overall accuracy: {avg_metrics['mean_accuracy']:.2f}%\n",
        "Average time: {avg_metrics['execution_time']:.2f}s\\n\"\"\"\n",
        "\n",
        "    print(summary_log)\n",
        "    with open(LOG_FILE, \"a\") as f:\n",
        "        f.write(summary_log)\n",
        "\n",
        "# Salvare rezultate detaliate\n",
        "results_df = pd.DataFrame(all_metrics)\n",
        "# results_df.to_csv(OUTPUT_FILE, index=False)\n",
        "# print(f\"\\n📊 Results saved to: {OUTPUT_FILE}\")\n",
        "print(f\"📄 Full log saved to: {LOG_FILE}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dpfTgCkAEe1",
        "outputId": "15f82ce3-45ef-4732-ed86-14c261e55633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "Run 1/5\n",
            "========================================\n",
            "Run 1 Results:\n",
            "✅ Correct: 2450 (100.00%)\n",
            "❌ Wrong: 0 (0.00%)\n",
            "🎯 Perfect: 490 (100.00%)\n",
            "⚠️ Mismatch: 0 (0.00%)\n",
            "📊 Accuracy: 100.00%\n",
            "⏱️ Time: 398.55s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 2/5\n",
            "========================================\n",
            "Run 2 Results:\n",
            "✅ Correct: 2450 (100.00%)\n",
            "❌ Wrong: 0 (0.00%)\n",
            "🎯 Perfect: 490 (100.00%)\n",
            "⚠️ Mismatch: 0 (0.00%)\n",
            "📊 Accuracy: 100.00%\n",
            "⏱️ Time: 392.08s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 3/5\n",
            "========================================\n",
            "Run 3 Results:\n",
            "✅ Correct: 2450 (100.00%)\n",
            "❌ Wrong: 0 (0.00%)\n",
            "🎯 Perfect: 490 (100.00%)\n",
            "⚠️ Mismatch: 0 (0.00%)\n",
            "📊 Accuracy: 100.00%\n",
            "⏱️ Time: 380.28s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 4/5\n",
            "========================================\n",
            "Run 4 Results:\n",
            "✅ Correct: 2450 (100.00%)\n",
            "❌ Wrong: 0 (0.00%)\n",
            "🎯 Perfect: 490 (100.00%)\n",
            "⚠️ Mismatch: 0 (0.00%)\n",
            "📊 Accuracy: 100.00%\n",
            "⏱️ Time: 377.67s\n",
            "\n",
            "\n",
            "========================================\n",
            "Run 5/5\n",
            "========================================\n",
            "Run 5 Results:\n",
            "✅ Correct: 2450 (100.00%)\n",
            "❌ Wrong: 0 (0.00%)\n",
            "🎯 Perfect: 490 (100.00%)\n",
            "⚠️ Mismatch: 0 (0.00%)\n",
            "📊 Accuracy: 100.00%\n",
            "⏱️ Time: 381.08s\n",
            "\n",
            "\n",
            "========================================\n",
            "FINAL SUMMARY AFTER 5 RUNS\n",
            "Average correct: 100.00%\n",
            "Average wrong: 0.00%\n",
            "Average perfect: 100.00%\n",
            "Average mismatch: 0.00%\n",
            "Overall accuracy: 100.00%\n",
            "Average time: 385.93s\n",
            "\n",
            "📄 Full log saved to: /content/drive/MyDrive/Quantum-LogFiles/6_quanutum_fidelity_ponderi_fixe_logs.txt\n"
          ]
        }
      ]
    }
  ]
}